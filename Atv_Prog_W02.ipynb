{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**Descrição da ponderada:**\n",
        "\n",
        "Objetivo: Otimizar um modelo de rede neural pré-treinado para detecção de fraudes em cartões de crédito. Aplicar técnicas avançadas de ajuste fino de hiperparâmetros, como grid search e random search, com o objetivo de aprimorar as métricas de desempenho do modelo, incluindo precisão, recall, F1-score e AUC-ROC. A atividade também exige uma comparação entre o modelo otimizado e o modelo original, permitindo avaliar o impacto das modificações nos hiperparâmetros sobre o desempenho geral."
      ],
      "metadata": {
        "id": "mPZA5KjWbkez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gdown\n",
        "import gdown"
      ],
      "metadata": {
        "id": "ewQolAMWMeqp",
        "outputId": "57bacfb5-3cb2-4efc-b630-f2bb87bf413a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arquivo_destino_colab = \"dataset.csv\"\n",
        "doc_id = \"1u_OWAPkIdgJw1ah5xP_dGBFMSANxjxEl\"\n",
        "URL = f\"https://drive.google.com/uc?id={doc_id}\"\n",
        "gdown.download(URL, arquivo_destino_colab, quiet=False)"
      ],
      "metadata": {
        "id": "kAlRxjfkMezc",
        "outputId": "3ed1d64a-1227-417a-ecd0-7d3b5f233960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1u_OWAPkIdgJw1ah5xP_dGBFMSANxjxEl\n",
            "From (redirected): https://drive.google.com/uc?id=1u_OWAPkIdgJw1ah5xP_dGBFMSANxjxEl&confirm=t&uuid=ab881cc9-6ed1-4365-8e35-c1504b40aaed\n",
            "To: /content/dataset.csv\n",
            "100%|██████████| 151M/151M [00:02<00:00, 52.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação e imports"
      ],
      "metadata": {
        "id": "4ZVcBzkUCsw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install scikeras imbalanced-learn --upgrade\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve,\n",
        "    precision_score, recall_score, f1_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)"
      ],
      "metadata": {
        "id": "CLJV0a8O9_Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982aa115-965f-4d72-9bb3-43a13ecd3dc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataset.csv\")"
      ],
      "metadata": {
        "id": "jjjd5jEi-BUP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ukOPscCAinZ",
        "outputId": "8482fec7-1418-4d05-d9fe-5f7174968c96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "1Ed1Ivr0-EZg",
        "outputId": "1144afda-8800-439f-8115-c60cdd5bbb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2a140fe-2879-4382-8723-2bd096e05545\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2a140fe-2879-4382-8723-2bd096e05545')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2a140fe-2879-4382-8723-2bd096e05545 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2a140fe-2879-4382-8723-2bd096e05545');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-05f44235-b66d-4203-979b-071d5bb1b953\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05f44235-b66d-4203-979b-071d5bb1b953')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-05f44235-b66d-4203-979b-071d5bb1b953 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "nuRbrTic-HSS",
        "outputId": "1a82076c-7c70-4fe2-b03d-fed9060e4a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
              "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
              "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
              "       'Class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daqui pra frente é o pré processamento ..."
      ],
      "metadata": {
        "id": "dgO0jubeNzK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação de features"
      ],
      "metadata": {
        "id": "jgw3EYZFDclC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alvo dataset:\n",
        "target_col = \"Class\"\n",
        "assert target_col in df.columns, f\"Coluna-alvo '{target_col}' não encontrada. Colunas: {df.columns.tolist()}\"\n",
        "\n",
        "# Remover colunas pouco úteis ou não normalizadas que atrapalham (Time)\n",
        "drop_cols = [c for c in [\"Time\"] if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=[target_col] + drop_cols, errors=\"ignore\")\n",
        "y = df[target_col].astype(int)\n",
        "\n",
        "# Sanidade: para o alvo binário\n",
        "assert set(np.unique(y)).issubset({0, 1}), \"A coluna alvo precisa ser binária (0/1).\"\n",
        "\n",
        "# Split estratificado\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "# Pesos de classe para desbalanceamento\n",
        "classes = np.array([0, 1])\n",
        "class_weights_values = compute_class_weight(\n",
        "    class_weight=\"balanced\", classes=classes, y=y_train\n",
        ")\n",
        "CLASS_WEIGHT = {int(k): float(v) for k, v in zip(classes, class_weights_values)}\n",
        "print(\"Class weights:\", CLASS_WEIGHT)\n",
        "\n",
        "# Kwargs de treino\n",
        "FIT_KW = {\n",
        "    \"clf__validation_split\": 0.1,\n",
        "    \"clf__class_weight\": CLASS_WEIGHT,\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4Dz3C9WC1Ji",
        "outputId": "77c1a2df-882a-4ed7-cbf8-a3797e962f65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: 0.5008661206149896, 1: 289.14340101522845}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento: imputação + padronização das features numéricas\n",
        "numeric_selector = make_column_selector(dtype_include=np.number)\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "        ]), numeric_selector),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "def build_mlp(meta,\n",
        "              hidden_layers=2,\n",
        "              units=64,\n",
        "              dropout=0.2,\n",
        "              l2=1e-4,\n",
        "              learning_rate=1e-3):\n",
        "    \"\"\"Usa 'meta' do SciKeras para obter n_features após o preprocess.\"\"\"\n",
        "    input_dim = meta[\"n_features_in_\"]\n",
        "    model = keras.Sequential(name=\"mlp_fraud\")\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(layers.Dense(units, activation=\"relu\",\n",
        "                               kernel_regularizer=regularizers.l2(l2)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        if dropout and dropout > 0:\n",
        "            model.add(layers.Dropout(dropout))\n",
        "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[keras.metrics.AUC(name=\"auc\"),\n",
        "                 keras.metrics.Precision(name=\"prec\"),\n",
        "                 keras.metrics.Recall(name=\"rec\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_auc\", patience=5, mode=\"max\", restore_best_weights=True\n",
        ")\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_auc\", factor=0.5, patience=3, mode=\"max\", min_lr=1e-6\n",
        ")\n",
        "\n",
        "baseline_clf = KerasClassifier(\n",
        "    model=build_mlp,\n",
        "    # hiperparâmetros baseline:\n",
        "    model__hidden_layers=2,\n",
        "    model__units=64,\n",
        "    model__dropout=0.2,\n",
        "    model__l2=1e-4,\n",
        "    model__learning_rate=1e-3,\n",
        "    epochs=30,\n",
        "    batch_size=512,\n",
        "    verbose=0,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        ")\n",
        "\n",
        "baseline_pipe = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", baseline_clf),\n",
        "])"
      ],
      "metadata": {
        "id": "CCHcW9YpiX_r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo baseline (MLP) + avaliação"
      ],
      "metadata": {
        "id": "FHuBnyz-DXNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino baseline\n",
        "baseline_pipe.fit(X_train, y_train, **FIT_KW)\n",
        "\n",
        "# Avaliação\n",
        "def proba_pos(p):\n",
        "    p = np.asarray(p)\n",
        "    if p.ndim == 2 and p.shape[1] == 2:\n",
        "        return p[:, 1]\n",
        "    return p.ravel()\n",
        "\n",
        "def evaluate(pipe, X, y, name=\"model\"):\n",
        "    # Tentativa padrão via Pipeline.predict_proba\n",
        "    try:\n",
        "        y_proba = proba_pos(pipe.predict_proba(X))\n",
        "    except Exception as e:\n",
        "        # Fallback: transforma manualmente e usa o estimador final\n",
        "        try:\n",
        "            Xt = pipe.named_steps[\"preprocess\"].transform(X)\n",
        "            y_proba = proba_pos(pipe.named_steps[\"clf\"].predict_proba(Xt))\n",
        "            print(f\"[Aviso] Fallback do predict_proba do Pipeline → estimador direto ({type(e).__name__}: {e})\")\n",
        "        except Exception as e2:\n",
        "            raise e2  # re-levanta se nem o fallback funcionar\n",
        "\n",
        "    y_pred  = (y_proba >= 0.5).astype(int)\n",
        "\n",
        "    auc  = roc_auc_score(y, y_proba)\n",
        "    pre  = precision_score(y, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y, y_pred)\n",
        "\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"AUC-ROC : {auc:.4f}\")\n",
        "    print(f\"Precisão: {pre:.4f}\")\n",
        "    print(f\"Recall  : {rec:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\nMatriz de confusão (verdadeiro x predito):\\n\", cm)\n",
        "    print(\"\\nRelatório de classificação:\\n\", classification_report(y, y_pred, digits=4, zero_division=0))\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y, y_proba)\n",
        "    prec, rec_, _ = precision_recall_curve(y, y_proba)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=\"--\")\n",
        "    plt.xlabel(\"FPR\")\n",
        "    plt.ylabel(\"TPR\")\n",
        "    plt.title(f\"ROC - {name}\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(rec_, prec, label=f\"{name}\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precisão\")\n",
        "    plt.title(f\"Precision-Recall - {name}\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()\n",
        "\n",
        "    return {\"model\": name, \"auc\": auc, \"precision\": pre, \"recall\": rec, \"f1\": f1}"
      ],
      "metadata": {
        "id": "SFj_XbbijyKh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_metrics = evaluate(baseline_pipe, X_test, y_test, name=\"Baseline\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BPSYDuAJlScC",
        "outputId": "2b77757b-f3de-4073-9a92-2fe1dd55b902"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Aviso] Fallback do predict_proba do Pipeline → estimador direto (AttributeError: 'super' object has no attribute '__sklearn_tags__')\n",
            "\n",
            "=== Baseline ===\n",
            "AUC-ROC : 0.9778\n",
            "Precisão: 0.0585\n",
            "Recall  : 0.9184\n",
            "F1-score: 0.1100\n",
            "\n",
            "Matriz de confusão (verdadeiro x predito):\n",
            " [[55416  1448]\n",
            " [    8    90]]\n",
            "\n",
            "Relatório de classificação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9999    0.9745    0.9870     56864\n",
            "           1     0.0585    0.9184    0.1100        98\n",
            "\n",
            "    accuracy                         0.9744     56962\n",
            "   macro avg     0.5292    0.9465    0.5485     56962\n",
            "weighted avg     0.9982    0.9744    0.9855     56962\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVglJREFUeJzt3Xd4FNX/9vH3piekUJNQQu8qICAIiIpEaWJBFEVpKjbwUfliQVDEBjbEgqJU/SmiIKACIkoRKYoiKEqR3hNAIAmB1D3PHyOLMQES2M1kd+/Xde1lzmRm57MjkDtnzjnjMMYYRERERHxEgN0FiIiIiLiTwo2IiIj4FIUbERER8SkKNyIiIuJTFG5ERETEpyjciIiIiE9RuBERERGfonAjIiIiPkXhRkRERHyKwo2IiJtNmTIFh8PBjh07XNuuvPJKrrzySttqEvEnCjciPu7kD9qTr6CgICpXrkzfvn3Zu3dvgccYY/i///s/Lr/8ckqXLk1ERAQXXXQRzz77LOnp6ac916xZs+jUqRPly5cnJCSESpUqccstt7Bo0SK3fqbq1avn+UxhYWHUqVOHRx99lMOHD7v1XCLifYLsLkBEisezzz5LjRo1yMjI4Mcff2TKlCksW7aMP/74g7CwMNd+ubm59OzZk88++4y2bdvyzDPPEBERwQ8//MCIESOYPn063333HXFxca5jjDHceeedTJkyhYsvvphBgwYRHx/P/v37mTVrFu3bt2f58uW0bt3abZ+nSZMm/O9//wMgIyOD1atXM2bMGL7//ntWrVrltvO4y4IFC+wuQcR/GBHxaZMnTzaA+fnnn/Nsf/zxxw1gPv300zzbX3zxRQOYwYMH53uvL7/80gQEBJiOHTvm2f7KK68YwDz88MPG6XTmO+7DDz80P/30kxs+jaVatWqmS5cu+bYPHjzYAOavv/5y27nOxclrvn37dlvrEPFXui0l4qfatm0LwNatW13bTpw4wSuvvELdunUZOXJkvmO6du1Knz59mD9/Pj/++KPrmJEjR1K/fn1effVVHA5HvuN69epFixYtPPRJTomPjwcgKOhUp/Tvv/9O3759qVmzJmFhYcTHx3PnnXfy999/5zk2LS2Nhx9+mOrVqxMaGkpsbCxXX301v/76a579fvrpJzp27EhMTAwRERFcccUVLF++/Ky1/XfMzZIlS3A4HHz22We88MILVKlShbCwMNq3b8+WLVvyHX+u5xXxRwo3In7q5GDXMmXKuLYtW7aMI0eO0LNnzzwB4d969+4NwJw5c1zHHD58mJ49exIYGOjZov8lOzubQ4cOcejQIfbs2cNXX33F6NGjufzyy6lRo4Zrv2+//ZZt27bRr18/3nrrLW699VamTZtG586dMca49rvvvvt49913uemmm3jnnXcYPHgw4eHhbNiwwbXPokWLuPzyy0lNTWX48OG8+OKLHD16lKuuuuqcb4WNGjWKWbNmMXjwYIYMGcKPP/7I7bffnmcfT5xXxKfZ3XUkIp518hbJd999Zw4ePGh2795tZsyYYSpUqGBCQ0PN7t27XfuOGTPGAGbWrFmnfb/Dhw8bwHTr1s0YY8wbb7xx1mPcrVq1agbI92rTpo05dOhQnn2PHz+e7/hPPvnEAGbp0qWubTExMWbAgAGnPafT6TR16tQxHTp0yHPr7fjx46ZGjRrm6quvdm0r6LbUFVdcYa644gpXe/HixQYwDRo0MJmZma7tJ6/nunXrinxeEbGo50bETyQmJlKhQgUSEhLo3r07pUqV4ssvv6RKlSqufdLS0gCIioo67fuc/F5qamqe/57pGE9o2bIl3377Ld9++y1z5szhhRde4M8//+S6667jxIkTrv3Cw8NdX2dkZHDo0CEuvfRSgDy3nEqXLs1PP/3Evn37Cjzf2rVr2bx5Mz179uTvv/929Rqlp6fTvn17li5ditPpLPLn6NevHyEhIa72yduF27Zt8+h5RXyZZkuJ+ImxY8dSt25dUlJSmDRpEkuXLiU0NDTPPicDysmQU5D/BqDo6OizHnM2Bw8eJDc319WOjIwkMjLyjMeUL1+exMREV7tLly7Uq1eP7t27M2HCBB588EEADh8+zIgRI5g2bRoHDhzI8x4pKSmur19++WX69OlDQkICzZo1o3PnzvTu3ZuaNWsCsHnzZgD69Olz2ppSUlLy3OYrjKpVq+Zpnzz+yJEjHj2viC9TuBHxEy1atKB58+YA3HDDDVx22WX07NmTTZs2uYJEgwYNAGsQ7g033FDg+/z+++8ANGzYEID69esDsG7dutMeczaXXHIJO3fudLWHDx/OM888U+T3ad++PQBLly51hZtbbrmFFStW8Oijj9KkSRMiIyNxOp107NgxT4/HLbfcQtu2bZk1axYLFizglVde4aWXXmLmzJl06tTJte8rr7xCkyZNCjz/2QJZQU43Tsn8Mx7IU+cV8WUKNyJ+KDAwkJEjR9KuXTvefvttnnjiCQAuu+wySpcuzdSpUxk6dGiBP3g//PBDAK699lrXMWXKlOGTTz7hySefPKdBxR9//HGeW0kne0uKKicnB4Bjx44BVu/HwoULGTFiBE8//bRrv5O9If9VsWJFHnjgAR544AEOHDhA06ZNeeGFF+jUqRO1atUCrJ6qf/cYeZpd5xXxZhpzI+KnrrzySlq0aMGYMWPIyMgAICIigsGDB7Np0yaGDh2a75i5c+cyZcoUOnTo4Bq3EhERweOPP86GDRt4/PHH88xAOumjjz4646yeNm3akJiY6Hqda7j56quvAGjcuDFwqlfkvzWNGTMmTzs3NzfPLSqA2NhYKlWqRGZmJgDNmjWjVq1avPrqq67w9G8HDx48p5rPxq7zingz9dyI+LFHH32Um2++mSlTpnDfffcB8MQTT7BmzRpeeuklVq5cyU033UR4eDjLli3jo48+okGDBnzwwQf53ufPP//ktddeY/HixXTv3p34+HiSkpKYPXs2q1atYsWKFW6tfe/evXz00UcAZGVl8dtvv/Hee+9Rvnx51y2p6OhoLr/8cl5++WWys7OpXLkyCxYsYPv27XneKy0tjSpVqtC9e3caN25MZGQk3333HT///DOvvfYaAAEBAUyYMIFOnTpxwQUX0K9fPypXrszevXtZvHgx0dHRrnDlTnadV8Sr2TxbS0Q87HQrFBtjTG5urqlVq5apVauWycnJybN98uTJpk2bNiY6OtqEhYWZCy64wIwYMcIcO3bstOeaMWOGueaaa0zZsmVNUFCQqVixounRo4dZsmSJWz/Tf6eCBwQEmNjYWHPbbbeZLVu25Nl3z5495sYbbzSlS5c2MTEx5uabbzb79u0zgBk+fLgxxpjMzEzz6KOPmsaNG5uoqChTqlQp07hxY/POO+/kO/eaNWtMt27dTLly5UxoaKipVq2aueWWW8zChQtd+xRlKvj06dPzvP/27dsNYCZPnlzk84qIxWFMAX3IIiIiIl5KY25ERETEpyjciIiIiE9RuBERERGfonAjIiIiPkXhRkRERHyKwo2IiIj4FL9bxM/pdLJv3z6ioqJwOBx2lyMiIiKFYIwhLS2NSpUqERBw5r4Zvws3+/btIyEhwe4yRERE5Bzs3r2bKlWqnHEfvws3UVFRgHVxoqOjba5GRERECiM1NZWEhATXz/Ez8btwc/JWVHR0tMKNiIiIlynMkBINKBYRERGfonAjIiIiPkXhRkRERHyKwo2IiIj4FIUbERER8SkKNyIiIuJTFG5ERETEpyjciIiIiE9RuBERERGfonAjIiIiPsXWcLN06VK6du1KpUqVcDgczJ49+6zHLFmyhKZNmxIaGkrt2rWZMmWKx+sUERER72FruElPT6dx48aMHTu2UPtv376dLl260K5dO9auXcvDDz/M3XffzTfffOPhSkVERMRb2PrgzE6dOtGpU6dC7z9u3Dhq1KjBa6+9BkCDBg1YtmwZr7/+Oh06dPBUmSIitjucnsXxrBy7yxAplJCgAGKjwmw7v1c9FXzlypUkJibm2dahQwcefvjh0x6TmZlJZmamq52amuqp8kREPGLO7/t48JM1GGN3JSKF07RqaWY+0Ma283tVuElKSiIuLi7Ptri4OFJTUzlx4gTh4eH5jhk5ciQjRoworhJFRNxu3d4UjIHAAAdBAQ67yxHJpwypODAcJgaA4EB75yt5Vbg5F0OGDGHQoEGudmpqKgkJCTZWJCJybvq1rs6waxvaXYZIXjuWw+ePQPm60GsWBATaXZF3hZv4+HiSk5PzbEtOTiY6OrrAXhuA0NBQQkNDi6M8ESmBjDGMmr+RrQfS7S7lnG0+kGZ3CSL5OZ2w7DVY/CIYJ4RGQfpBiIq3uzLvCjetWrVi3rx5ebZ9++23tGrVyqaKRKSk25Scxnvfb7O7DLcoF6lf1KSEOHYAZt4D2xZb7ca3QedXITTS3rr+YWu4OXbsGFu2bHG1t2/fztq1aylbtixVq1ZlyJAh7N27lw8//BCA++67j7fffpvHHnuMO++8k0WLFvHZZ58xd+5cuz6CiJRw2TnWKNzosCCe7NzA5mrOXURoENc0jDv7jiKetu17mNkfjiVDcAR0eQ2a9LS7qjxsDTe//PIL7dq1c7VPjo3p06cPU6ZMYf/+/ezatcv1/Ro1ajB37lweeeQR3njjDapUqcKECRM0DVzEi53IymXN7iMemwm07ZB1O6pUaBC3tqjqmZOI+IvcHJj3qBVsKjSAm6dAbH27q8rHYYx/TS5MTU0lJiaGlJQUoqOj7S5HxO/d/cEvfLch+ew7nqfKpcNZ/sRVHj+PiM9LWge/TIJrXoCQiGI7bVF+fnvVmBsR8T17jhwHoEqZcCJDPfdP0q2XaJakyDnZshBSdkOzvlY7/iK49nVbSzobhRsRKRFGdWvEZXXK212GiJyUmwNLXoQfRkNAEFRsApWa2F1VoSjciK3eX7qV6b/ssbsMsdHOv4/bXYKI/FfKXvj8Lti10mo37QUVSt7YmtNRuBFbTfhhOwfSMs++o/i8KmUKXqtKRIrZXwtg1r1w4jCERMF1b8KF3eyuqkgUbsRWzn+Gs79000VULVvK3mLENpVLh1O1XPENTBSR01j4LPxgPZyaio2t2VBla9pa0rlQuJFisWzzIXb8nX+F2IzsXAAaVSlNg4qavSYiYqvwMtZ/W9wL1zwHQd65cKTCjXjc9kPp3DHxpzPuExJk70PWRET8VlY6hPzTc95qIFRuDtW8e+V/hRvxuMPp1pia8OBALq+bfzZM3bgoapbXLSkRkWKVkwXfPg1bF0L/xdajExwOrw82oHAjxSg2OpT3ejW3uwwRETm8HWb0g31rrPZf8+Gi7vbW5EYKNz5m/b5U+kxexdHjWXaX4uL0qzWwRURKuPVfwBcDITMVwkrDjeOgXie7q3IrhRsf89P2vzlYQqdWX5xQ2u4SRET8V3YGLBgGP4+32gkt4aaJUNr3Vu9WuPFRLaqX5c3bLra7DBeHA2KjvHPUvYiIT/j2qVPBps3DcNUwCAy2tSRPUbjxcmt2HeHrP5I4+fzTP/amAhAXE0Z8TJidpYmISEnSdjDsWAZXPwd1Eu2uxqMUbrzckJnr2JiUlm97ZGigDdWIiEiJkX0CNsyBRjdb7ag4uG85BPj+0hsKN17ueJa1CN4NTSoR909PTWhQID30BGQREf918C+Y3hcO/AkBgacen+AHwQYUbmx1MC2TzJzc83qPnFwnAL1bV6dp1TLuKEtERLzZ2k9g7iDIPg6lKpxaddiPKNzY5MOVO3j6iz/tLkNERHxFVjrMewzWfmS1a1wO3cZDVLy9ddlA4cYmv+1OASAwwEFQgOO83qtG+VLUj49yR1kiIuKNDmywbkMd3AiOALjiCbh8sHVLyg8p3NjssQ71uPeKWnaXISIi3uzwdivYRMbDTROgRlu7K7KVwo0Nxi7ewoqth+wuQ0REvJkx1iJiAPU7w3VvQd1OEFnB3rpKAP8YNl2C/H0sk1e+2cT+lAwAykVqYTsRESmipHUwqQOk7Dm1rWlvBZt/KNwUs5x/HrTkcMC4O5pyfZNKNlckIiJewxj4ZRKMbw+7f4JvhtpdUYmk21I2CXA46HhhRbvLEBERb5GRCl89BH/OtNp1OkCX0fbWVEIp3IiIiJR0+9bCjH5weBsEBEH74dBqoN8syldUCjciIiIl2fal8NFNkJsFMQnQfTIkXGJ3VSWawo2IiEhJVuUSKFcHylSH69+GiLJ2V1TiKdwUow9W7OCDlTvsLkNEREq6AxugfF1rEb7gcOg7x3qMguP8Fn31F7pZV4wmLd/OtoPpACSUCbe5GhERKXGMgZVjYVxb+OFfg4UjyirYFIF6boqR01jTwJ+7/gKua1LZ5mpERKREOX4YZj8Af31ttQ+sz7tQnxSawo0bncjK5Zs/kziWmVPg949lWNsvrBxDTHhwcZYmIiIl2a6fYMadkLoHAkOgw4twyd0KNudI4caNPvpxJy/M23DW/UKCdDdQREQApxNWvAkLnwWTC2Vrws1ToGJjuyvzago3bnTwWCZgPaW7blxkgfvUKB9Jg/jo4ixLRERKqiPbYfGLVrC5sDt0HQOhUXZX5fUUbtwoJ9caU9Pxwnge71jf5mpERKTEK1cLOr8CGGjaR7eh3EThxo1ODhgO1B9OEREpiNMJy0ZDzXZQpZm1rVkfe2vyQRr84UY5TicAgQEKNyIi8h/HDsBH3WDRczCjL2Sl212Rz1LPjRvlWtlG4UZERPLa9j3M7A/HkiEoHK54AkJK2V2Vz1K4caM9R44DCjciIvIPZy58/zJ8/xJgoEIDazZUrMZlepLCjRudDDVpGQWvcyMiIn4kIxWm9YQdP1jti++ATq9ASIS9dfkBhRs3igy1LmepkECbKxEREduFREJwBASXgmtfh8Y97K7IbyjcuNE/k6WI1urDIiL+KTcHnNnWwy4DAuDGcXD8byhfx+7K/IpmS7lRrtNKNwEacyMi4n9S9sIHXWHOI6e2RZRVsLGBwo0b5f7TdaNsIyLiZ/5aAOMug10rYMMcOLLT7or8mm5LuZHTqUX8RET8Sm629VyoFW9a7YqNoftkKFPN3rr8nMKNG51coVi3pURE/MDR3daTvPesstot7oVrnoOgUHvrEoUbd/rn0VLquRER8XVOJ3x0ExzaBKExcP3b0PA6u6uSf2jMjRu5bkup50ZExLcFBECnUVDlErhvqYJNCaOeGzc6cjwL0ENdRUR80uHtcGQ71LrKate6CmpcaQUdKVH0f8SN/tyXancJIiLiCeu/gPcuh8/6wOFtp7Yr2JRI6rlxo5CgALJynNSJjbK7FBERcYfsDFgwDH4eb7WrtIAALdRa0inceEDpCP3BFxHxen9vhel9Iel3q93mIbjqKQjUv/ElncKNiIjIf62bAV89DFlpEF4WbnwP6l5jd1VSSAo3IiIi/7V3tRVsqraGmyZATGW7K5IiULhxJ2N3ASIics6MOTXdNXEElK0JzfpBoH5UehsN8/YATQUXEfEyv30KH99sPdUbICgEWvRXsPFSCjciIuK/stJh9gCYdQ9s+RbWfmR3ReIGiqQiIuKfDmywZkMd3Ag44Mon4OJedlclbmB7z83YsWOpXr06YWFhtGzZklWrVp1x/zFjxlCvXj3Cw8NJSEjgkUceISMjo5iqPTOjQTciIiWfMbDmI3i/nRVsIuOgz5dWuAkItLs6cQNbe24+/fRTBg0axLhx42jZsiVjxoyhQ4cObNq0idjY2Hz7T506lSeeeIJJkybRunVr/vrrL/r27YvD4WD06NE2fIKCOdCgGxGREmvJKPh+lPV1zXbQbTxEVrC3JnErW3tuRo8eTf/+/enXrx8NGzZk3LhxREREMGnSpAL3X7FiBW3atKFnz55Ur16da665httuu+2svT0iIiIuF3aD0GhrQb47ZirY+CDbwk1WVharV68mMTHxVDEBASQmJrJy5coCj2ndujWrV692hZlt27Yxb948OnfufNrzZGZmkpqamuclIiJ+xBjY//updoV68NBvcPlgPRvKR9n2f/XQoUPk5uYSFxeXZ3tcXBxJSUkFHtOzZ0+effZZLrvsMoKDg6lVqxZXXnklTz755GnPM3LkSGJiYlyvhIQEt36OfzMaciMiUrJkpMLnd8H7V8DOFae2R5S1rybxOK+KrEuWLOHFF1/knXfe4ddff2XmzJnMnTuX55577rTHDBkyhJSUFNdr9+7dHq9T69yIiJQA+3+zQs0fnwMOOLjJ7oqkmNg2oLh8+fIEBgaSnJycZ3tycjLx8fEFHvPUU0/Rq1cv7r77bgAuuugi0tPTueeeexg6dCgBBXQvhoaGEhoa6v4PICIiJZMx8PME+OZJyM2CmAToPgkSWthdmRQT23puQkJCaNasGQsXLnRtczqdLFy4kFatWhV4zPHjx/MFmMBAa9qe0T0hERE5cRQ+6w3zBlvBpl5nuHepgo2fsXUq+KBBg+jTpw/NmzenRYsWjBkzhvT0dPr16wdA7969qVy5MiNHjgSga9eujB49mosvvpiWLVuyZcsWnnrqKbp27eoKOSIi4sc2zoUNX0JAMFz9LFx6v8YK+CFbw02PHj04ePAgTz/9NElJSTRp0oT58+e7Bhnv2rUrT0/NsGHDcDgcDBs2jL1791KhQgW6du3KCy+8YNdHyEN9RyIiNmvSE5L/hItugsrN7K5GbOIwfnY/JzU1lZiYGFJSUoiOjnbre9d6ch65TsOqJ9sTGx3m1vcWEZECHD8Mi56HxOEQFmN3NeJBRfn5rWdLiYiId9q9CmbcCSm7ITMVbppgd0VSQijciIiId3E6YeVbsPBZcOZAmRrQaqDdVUkJonDjRn52h09EpPil/w2z74PNC6z2Bd2g6xsQ5t5hBuLdFG48QQPzRUTcb//vMLUHpO2DwFDo9BI066vZUJKPwo2IiHiH6MrWf8vVgZunQPyFtpYjJZfCjYiIlFwZqaduOZUqB71mWisOh0baW5eUaF71bKmSTiNuRETcaPtSeLs5rJ16altsAwUbOSuFGw9waNCNiMi5c+bCklHw4fVwLBlWjbdmSIkUkm5LiYhIyZGWBDP7W702AE3ugM4vQwEPRhY5HYUbEREpGbYugpn3QPpBCC4F146GxrfaXZV4IYUbERGx3+Ht8FF3MLkQe4E1G6pCXburEi+lcONGWsNPROQcla0Blz1sPSuq40gIDre7IvFiCjceoPWkREQKYfO3UK62FWwArnpK/4CKW2iEloiIFK/cbFjwFHzc3XrwZU6WtV3BRtxEPTciIlJ8ju62As2eVVa7cjO0Spi4m8KNiIgUj43zYPb9kHEUQmPg+reg4fV2VyU+SOHGA9SxKiLyLzlZ8N0z8ONYq12pKXSfdGqsjYibKdyIiIiHGdi53Pry0gcgcQQEhdhbkvg0hRsREfEMY6xBwkGh1ro1B9ZD/S52VyV+QOHGTYwWuRERseRkwoJhEBYDVw2ztpWtodtQUmwUbjzAoemMIuKv/t4KM/rB/t/AEQCNb4NyteyuSvyMwo2IiLjHHzPhy/8HWWkQXhZuHKdgI7ZQuBERkfOTfQLmD4HVk6121VZw00SIqWxvXeK3FG5EROTcGQMfXg+7fwIc0HYQXPkkBOrHi9hHf/rcROOJRcQvORzQtI811qbb+1C7vd0ViSjceIKGE4uIT8s6Dim7oUI9q33x7VC/M4SXsbcukX/owZkiIlJ4BzbC+Kvg/26E44dPbVewkRJE4UZERApnzcfw/pVwcAM4c+DoTrsrEimQbku5iYbciIjPyjwG8wbDb59Y7ZpXQrfxEBlra1kip6Nw4wFaw09EfEbynzC9Lxz6y1qUr92TcNn/IEAd/1JyKdyIiMjpLRtjBZuoitbaNdXb2F2RyFkp3IiIyOl1eRWCw6D9cChV3u5qRApF/YpuogdniohP2P+b9dDLk/+mhcXAdW8p2IhXUc+NBzi00o2IeBtj4OcJ8M2TkJsFFerDxXfYXZXIOVG4ERHxdxkp8OWDsP4Lq123E9TrbG9NIudB4UZExJ/tXQ3T+1lr1gQEw9Uj4NIHNO1TvJrCjYiIv/r1/2DOI+DMhtJVofsUqNLM7qpEzpvCjZtoOLGIeJ2yNcHkQoOucN3bEF7a7opE3ELhxhPUmysiJdWJo6dCTPU2cPdCqHSxbkOJT9FUcBERf+B0wvI34Y1GcPCvU9srN1WwEZ+jcCMi4uvS/4ZPboVvn7JmRv0+ze6KRDxKt6XcRGv4iUiJtHMlfH4XpO6FwFDoNAqa9bO7KhGPUrjxAPXwiojtnE5Y/josesEaNFyuNtw8BeIvsrsyEY9TuBER8UVrP4aFz1pfN+oBXUZDaKS9NYkUE4UbERFf1Pg2+ONzuPAm6zEK6lIWP6Jw4yZGK92IiJ2cufDrh9DkdggKgcAg6DVLoUb8ksKNB+ifEhEpVmnJMPNu2L4UDm2Gji9a2xVsxE8p3IiIeLOti2HmPZB+AIIjoGIjuysSsZ3CjYiIN8rNge9HwdJXAQOxF1izoSrUtbsyEdsp3IiIeJvUffD53bBzudVu2gc6vQTB4fbWJVJCKNy4iRbxE5Fik30C9v8OIZHQ9Q24qLvdFYmUKAo3HuDQID4RcTdjTg0QLlfLugVVtob1tYjkoWdLiYiUdCl7YHJna/DwSXUSFWxETkPhRkSkJNv0NYy7DHatgHmDrfVsROSMdFtKRKQkysmChSNg5dtWu9LF0H0yBATaW5eIF1C48QCNuBGR83JkJ8zoB3tXW+2W98PVIyAo1N66RLyE7belxo4dS/Xq1QkLC6Nly5asWrXqjPsfPXqUAQMGULFiRUJDQ6lbty7z5s0rpmpFRDwsZQ+819YKNmEx0ONj6DRKwUakCGztufn0008ZNGgQ48aNo2XLlowZM4YOHTqwadMmYmNj8+2flZXF1VdfTWxsLDNmzKBy5crs3LmT0qVLF3/xIiKeEF0Z6naCw1uh+yQoXdXuikS8jq3hZvTo0fTv359+/foBMG7cOObOncukSZN44okn8u0/adIkDh8+zIoVKwgODgagevXqxVnyaWmdGxE5Z4e3QVhpiChrTfe+9nUIDLZeIlJktt2WysrKYvXq1SQmJp4qJiCAxMREVq5cWeAxX375Ja1atWLAgAHExcVx4YUX8uKLL5Kbe/rZA5mZmaSmpuZ5eZqWuRGRQvtjJoy7HGY/cOq3pJAIBRuR82BbuDl06BC5ubnExcXl2R4XF0dSUlKBx2zbto0ZM2aQm5vLvHnzeOqpp3jttdd4/vnnT3uekSNHEhMT43olJCS49XOIiJyT7AyY84g1cDgrDU4cgUzP//Il4g9sH1BcFE6nk9jYWN5//32aNWtGjx49GDp0KOPGjTvtMUOGDCElJcX12r17dzFWLCJSgENbYEIi/DLJal82CPrOtQYQi8h5s23MTfny5QkMDCQ5OTnP9uTkZOLj4ws8pmLFigQHBxMYeGqdhwYNGpCUlERWVhYhISH5jgkNDSU0VLMMRKSE+P0z+OphyE6HiPLQ7T2onXjWw0Sk8GzruQkJCaFZs2YsXLjQtc3pdLJw4UJatWpV4DFt2rRhy5YtOJ1O17a//vqLihUrFhhsipNBI4pF5CyyjsOi56xgU70t3LdMwUbEA2y9LTVo0CDGjx/PBx98wIYNG7j//vtJT093zZ7q3bs3Q4YMce1///33c/jwYR566CH++usv5s6dy4svvsiAAQPs+ggFcmgZPxEpSEgEdJ8CVzwBvb+A6Ip2VyTik2ydCt6jRw8OHjzI008/TVJSEk2aNGH+/PmuQca7du0iIOBU/kpISOCbb77hkUceoVGjRlSuXJmHHnqIxx9/3K6PICJyZmunWs+DatrLaldpZr1ExGMcxvjXCi2pqanExMSQkpJCdHS02973eFYODZ/+BoANz3YkPETPfxHxa5nHrAdd/vYJBIbC/SugfG27qxLxWkX5+a1nS7mJf0VEETmj5D9hel849Bc4AuDyR6FsDburEvEbCjceoEX8RPyUMfDrh/D1Y5CTAVEV4aYJUP0yuysT8SsKNyIi7mAMzLoPfp9mtWsnwo3vQany9tYl4ocUbkRE3MHhgHK1wBEI7Z+C1g9BgFetkyriMxRu3ERDbkT8kDGQcRTCy1jttv+Dep0g/iJbyxLxd/q1QkTkXGSkWIOGp1wL2SesbQGBCjYiJYB6bkREimrvr9YDL4/sgIAg2PUj1Gpnd1Ui8g+FGxGRwjIGfnoPFgwDZzbEVIWbJ0OV5nZXJiL/onAjIlIYJ47AFwNh4xyrXf9auP7tU+NtRKTEULhxEz9b6FnE/8z9nxVsAkPgmuehxT1a1EqkhFK48QD9eyfigxJHwOHtcO1oqHSx3dWIyBlotpSISEGOH4Y1H59ql06A/osUbES8gHpuRET+a9ePMONOSN0LEWWttWtA3bIiXkLhxk004kbEBzidsHwMLHoeTC6UrQXRle2uSkSKSOHGAxzotzsRr3PsIMy6F7YutNoX3QzXvg6hUfbWJSJF5rYxNzNnzqRRo0buejsRkeKzYxmMu8wKNkFhcN1b0G28go2IlypSuHnvvffo3r07PXv25KeffgJg0aJFXHzxxfTq1Ys2bdp4pEgREY9KS4JjSVC+HvRfDE17a3yNiBcr9G2pUaNG8fTTT9OoUSM2btzIF198wdChQ3nrrbd46KGHuPfeeylTxn8Xs9IyNyJexphTAeai7pCbDQ2vg5BS9tYlIuet0D03kydPZvz48fzyyy98/fXXnDhxghUrVrBlyxaeeOIJvw42/6Vf+ERKuG1L4L22kJZ8aluT2xRsRHxEocPNrl27uOqqqwBo27YtwcHBjBgxglKl9I+BiHgJZy4segE+vAGS1sH3o+yuSEQ8oNC3pTIzMwkLC3O1Q0JCKFu2rEeKEhFxu9T98PndsHOZ1W7aG655wd6aRMQjijQV/KmnniIiIgKArKwsnn/+eWJiYvLsM3r0aPdVJyLiDlu+g5n3wPG/ISQSrh0DjW62uyoR8ZBCh5vLL7+cTZs2udqtW7dm27ZtefZx+PNgEw0oFimZ/pwF0/taX8ddBDdPgfK17axIRDys0OFmyZIlHizDt/hxxBMpeWonQrnaUPNK6zZUcNhZDxER71ak21Kpqan89NNPZGVl0aJFCypUqOCpukREzt3un6FKc2vqYmiUtXZNWLTdVYlIMSn0bKm1a9dSv359OnToQNeuXalduzbffPONJ2sTESmanCz4ZihMTIQf3zm1XcFGxK8UOtw8/vjj1KhRg+XLl7N69Wrat2/PwIEDPVmbVzEadCNiryM7YXInWPm21U7dZ289ImKbQt+WWr16NQsWLKBp06YATJo0ibJly5Kamkp0tH4r+je/HlgtYocNc+CLByAjBcJi4Pp3oMG1dlclIjYpdLg5fPgwVapUcbVLly5NqVKl+PvvvxVuRMQeOZnw7dPw0zirXbk5dJ8EZarZW5eI2KpIA4rXr19PUlKSq22MYcOGDaSlpbm26cngIlJsDm6EnydYX7caCO2HQ1CIvTWJiO2KFG7at2+P+c8TIq+99locDgfGGBwOB7m5uW4t0FvowZkiNqjYGDq9DNGVoV5Hu6sRkRKi0OFm+/btnqzDp2jEjYiHZGfAd8Ph4l4Qf6G17ZK77K1JREqcQoebDz74gMGDB7sevyAiUqwObbFWGk5eB1sXwf0rIbBInc8i4icKPRV8xIgRHDt2zJO1iIgU7Pfp8P4VVrCJKA8dRyrYiMhpFfpfh/+OtRER8bis4zD/cfj1Q6td7TK4aQJEV7S3LhEp0Yr0q4/Wbzk9RT8RN0tLhv+7AQ6sBxxwxWNw+WPqsRGRsyrSvxJ169Y9a8A5fPjweRXkC5QBRdygVPl/XrFw03jrwZciIoVQpHAzYsQIYmJiPFWLiPi7rHRwBFpP7g4IhG7/rGETFWdvXSLiVYoUbm699VZiY2M9VYuI+LPk9dZsqOpt4NrXrW0KNSJyDgo9W0rjbc5MA65FzpEx1oDh8e3g0CbY9DUc1+1tETl3mi3lAQqCIoWUmQZzBsG6z6x2rfbQ7X2IKGtvXSLi1QodbpxOpyfrEBF/k7TOug319xZrnM1Vw6DNwxBQ6A5lEZECaU6liBS/nEz4+GZI2289F6r7JKh6qd1ViYiPULgRkeIXFApdRsOvH8AN7+o2lIi4lcKNm2hEkshZ7FsDJ45CrXZWu35nqNdJC0OJiNvp5raIeJYx8NN7MPEamNEPUvac+p6CjYh4gHpuRMRzThyBLwbCxjlWu9o1EFLK3ppExOcp3IiIZ+z5xeqpOboLAkPgmuehxT3qrRERj1O4cRMtAyTyD2Ng5Vj4bjg4c6BMdbh5ClS62O7KRMRPKNy4mX4pFb/ncMChv6xg0/AGuO5NCNMz6USk+CjciIh7OJ2nFuDr9BJUvwwuulmJX0SKnWZLicj5cTph2esw9Rbra4DgcGh0i4KNiNhCPTduYrTSjfij9EMw617Y8p3V3jQXGnS1tyYR8XsKN26m31PFb+xYDp/fZT1CISgMOr8C9a+1uyoREYUbESkiZy78MBqWvAjGCeXrWbOh4hraXZmICKBwIyJFNXcQrJ5ifd3kdqvHRgvziUgJUiIGFI8dO5bq1asTFhZGy5YtWbVqVaGOmzZtGg6HgxtuuMGzBYrIKc3vgvAycMM4uOEdBRsRKXFsDzeffvopgwYNYvjw4fz66680btyYDh06cODAgTMet2PHDgYPHkzbtm2LqdKz0Hhi8VXOXNj9r184KjaCh/+AJrfZV5OIyBnYHm5Gjx5N//796devHw0bNmTcuHFEREQwadKk0x6Tm5vL7bffzogRI6hZs2YxVnt2Dk19FV+Suh8+uA4md4a9q09tD420ryYRkbOwNdxkZWWxevVqEhMTXdsCAgJITExk5cqVpz3u2WefJTY2lrvuuqs4yhTxT1u+g3GXwc5lEBQKaUl2VyQiUii2Dig+dOgQubm5xMXF5dkeFxfHxo0bCzxm2bJlTJw4kbVr1xbqHJmZmWRmZrraqamp51yviF/IzYHFz1sL8wHEXWTNhipf29ayREQKy/bbUkWRlpZGr169GD9+POXLly/UMSNHjiQmJsb1SkhI8EhtGnIjPiFlD0zpcirYXHI33P2dgo2IeBVbe27Kly9PYGAgycnJebYnJycTHx+fb/+tW7eyY8cOunY9tQKq85/l3oOCgti0aRO1atXKc8yQIUMYNGiQq52amuqxgANaxE+83IavYPePEBptPfDyghvtrkhEpMhsDTchISE0a9aMhQsXuqZzO51OFi5cyMCBA/PtX79+fdatW5dn27Bhw0hLS+ONN94oMLSEhoYSGhrqkfpFfE6Le60Vh5v1hbIla7C+iEhh2b6I36BBg+jTpw/NmzenRYsWjBkzhvT0dPr16wdA7969qVy5MiNHjiQsLIwLL7wwz/GlS5cGyLddRArh6C5Y9AJ0ec2aARUQAFc/a3dVIiLnxfZw06NHDw4ePMjTTz9NUlISTZo0Yf78+a5Bxrt27SIgoOQPDTIadCPeZuNcmH0/ZKRYC/FdO9ruikRE3MJhjH/9WE5NTSUmJoaUlBSio6Pd9r5JKRlcOnIhwYEONr/Q2W3vK+J2OVnw7dPw07tWu3Iz6D4ZylSzty4RkTMoys9v23tuRKQYHd4OM/rBvjVWu9VAaD8cgkLsrUtExI0UbkT8xfYfYFpPyEw99Wyoeh3trkpExO0UbkT8Rfk61krDsZdC94kQU8XuikREPELhxk2MlvGTkij9byhVzvo6Kh76zoOyNSAw2N66REQ8qORPQ/IyDi3jJyXFuhnwRmP4c/apbRXqKtiIiM9TuBHxNdkn4Mv/B5/fBVlp8Ns0uysSESlWui0l4ksO/gXT+8KBPwEHXP4oXPG43VWJiBQrhRs38a/VgqREWvsJzB0E2cehVCx0ex9qtbO7KhGRYqdw424aciN22LcWZt9nfV3jcug2AaLibC1JRMQuCjcivqBSE2tBvrAYaPs/CAi0uyIREdso3Ih4I2Pgt0+gxhUQU9na1uEFe2sSESkhNFvKTTTkRopNZhrMvMd66OXnd0Fujt0ViYiUKOq5cTMNuRGPSlpnzYb6ews4AqHONeDQ7ygiIv+mcCPiDYyB1ZPh6ycgNxOiK0P3SVD1UrsrExEpcRRuREq6zDT48kH4c5bVrtsRbngXIsraW5eISAmlcCNS0jkC4eAmCAiCxGesWVEO3QAVETkdhRs3MVrFT9zJGOsVEAAhEXDzFMhIhYRL7K5MRKTE00hEN9Mv1HLeThyFz3rB8tdPbatQT8FGRKSQFG5ESpI9q+G9trDhK/j+FTh2wO6KRES8jm5LiZQExsCP78C3w8GZDWWqQ/fJEBlrd2UiIl5H4cZNNORGztnxwzD7Afjra6vd8Hq47i3rUQoiIlJkCjdu5tAyflIUOVkwIREOb4XAUOj4IjS/S4O3RETOg8bciNgpKAQuvR/K1oK7v4NL7lawERE5T+q5ESlu6X9D+kGIrW+1L7kbmtxuTfkWEZHzpp4bkeK0cwWMawOf9ICMFGubw6FgIyLiRgo3bqY7ClIgpxOWvgJTukDafggMgfRDdlclIuKTdFtKxNOOHYCZ98C2xVa7cU/o8iqElLK3LhERH6VwI+JJ276Hmf3hWDIER0CX16BJT7urEhHxaQo3Ip704ztWsKnQwHo+1MlBxCIi4jEKN26iRfykQNe/Yz0j6sonNWhYRKSYaECxm2k8sZ/bshC+GXqqXaocXPO8go2ISDFSz42IO+TmwJIX4YfRgIGEltDwOrurEhHxSwo3IucrZS98fjfsWmG1m98Jda62tyYRET+mcOMmBg268Ut/LYBZ98KJwxASBde9CRd2s7sqERG/pnDjZg6t4uc/lr4Ki56zvq7YBG6eDGVr2lqSiIgo3Iicu0pNAAe0uAeueQ6CQu2uSEREULgRKZpjByGygvV17UQY8BNUqGdvTSIikoemgruJ1rnxcTlZMH8IvN0MDm8/tV3BRkSkxFG4cTONuPFBR3bApA7WasMZKbDlO7srEhGRM9BtKZEzWf8FfPEgZKZAeBm44V2o18nuqkRE5AwUbkQKkp0BC4bBz+OtdkJLuGkilE6wty4RETkrhRuRgvw07lSwafMwXDUMAoNtLUlERApH4cZNNJ7Yx1x6P+z4AVrep9WGRUS8jAYUu5tGFHun7BOw/E3rGVFgrVlzx+cKNiIiXkg9NyIH/4LpfeHAn9ZsqPZP2V2RiIicB4Ub8W+/TYM5gyA7HUrFQvXL7K5IRETOk8KNmxit4uddstJh3mOw9iOrXeNy6DYBouLsrUtERM6bwo2baciNFzi4CT7rDQc3giMArngCLh8MAYF2VyYiIm6gcCP+xzjhyE6IjIebJkCNtnZXJCIibqRwI/7BmXuqZya2Adz6EcQ3PvUQTBER8RmaCu4mGnFTgiWtg3dbw86Vp7bVTlSwERHxUQo3buZwaNRNiWEM/DIJxre3xtd8+5Qe3y4i4gd0W0p8U0YqfPUQ/DnTate5Bm4YBwqfIiI+T+FGfM++tTCjHxzeBgFB0H44tBoIAeqoFBHxBwo34luS18PEqyE3C2ISoPskSGhhd1UiIlKMFG7cREM5SojYBlC3gzU76vqxEFHW7opERKSYlYh++rFjx1K9enXCwsJo2bIlq1atOu2+48ePp23btpQpU4YyZcqQmJh4xv2Lm4Z02GDvr9YzocD6H9BtPNw6VcFGRMRP2R5uPv30UwYNGsTw4cP59ddfady4MR06dODAgQMF7r9kyRJuu+02Fi9ezMqVK0lISOCaa65h7969xVy52M4YWDkWJl5jDR4+2X0WHK6UKSLix2wPN6NHj6Z///7069ePhg0bMm7cOCIiIpg0aVKB+3/88cc88MADNGnShPr16zNhwgScTicLFy4s5srFVscPw7Se8M2T4My2Vh3OzbK7KhERKQFsDTdZWVmsXr2axMRE17aAgAASExNZuXLlGY485fjx42RnZ1O2rN23IDToptjsXgXj2sKmeRAYAp1fhZs/gKBQuysTEZESwNYBxYcOHSI3N5e4uLxPYo6Li2Pjxo2Feo/HH3+cSpUq5QlI/5aZmUlmZqarnZqaeu4FF4JuhniQ0wkr3oSFz4LJhbI14eYpULGx3ZWJiEgJYvttqfMxatQopk2bxqxZswgLCytwn5EjRxITE+N6JSQkFHOV4jYZR+GncVawubA73LtUwUZERPKxNdyUL1+ewMBAkpOT82xPTk4mPj7+jMe++uqrjBo1igULFtCoUaPT7jdkyBBSUlJcr927d7uldrFBRFm4aSJ0fcN6mndolN0ViYhICWRruAkJCaFZs2Z5BgOfHBzcqlWr0x738ssv89xzzzF//nyaN29+xnOEhoYSHR2d5+UJWufGA5xOWPoK/PbpqW3V20CzvpoNJSIip2X7In6DBg2iT58+NG/enBYtWjBmzBjS09Pp168fAL1796Zy5cqMHDkSgJdeeomnn36aqVOnUr16dZKSkgCIjIwkMjLSts9xkh6c6SbHDsDMe2DbYgiOgBptIbqS3VWJiIgXsD3c9OjRg4MHD/L000+TlJREkyZNmD9/vmuQ8a5duwj41zOB3n33XbKysujevXue9xk+fDjPPPNMcZYunrJ9KXx+NxxLhqBw6PwKRFW0uyoREfEStocbgIEDBzJw4MACv7dkyZI87R07dni+ILGHM9e6DfX9S9a6NRUaWLOhYuvbXZmIiHiREhFuRMjNgY+6wfbvrfbFvaDTyxASYW9dIiLidRRu3ETjic9TYBBUbgp7foGuY6DRLXZXJCIiXkrhxs00nLgIcnOstWtKlbfa7YZC097W4nwiIiLnyKsX8RMvlrIXPrgWPr4Zcv55JlRgsIKNiIicN/XcSPH7awHMuhdOHIaQKDiwHio1sbsqERHxEQo3bqJF/AohN9t6LtSKN612xcbQfTKUq2VvXSIi4lMUbtxMa/idxtFdMONO2POz1W5xL1zznJ7kLSIibqdwI8XjywetYBMaA9e/DQ2vs7siERHxURpQLMWjy2ioeSXct1TBRkREPErhxk2MVrrJ68gOWP3BqXa5WtD7CyhT3a6KRETET+i2lNtp0A3rv4AvHoTMVChdFWq1s7siERHxIwo34j7ZGbBgGPw83mpXaaGZUCIiUuwUbsQ9/t4K0/tC0u9Wu81DcNVT1sJ8IiIixUjhRs7fn7Os21BZaRBeFm58D+peY3dVIiLipxRu3MSvF/HLSreCTdXWcNMEiKlsd0UiIuLHFG7czG8W8cvNsZ7kDdDkdggpBfW7ntomIiJiE00Fl6L7bRq82xqOH7baDgdccKOCjYiIlAgKN1J4Wekwe4D10MtDm+CncXZXJCIiko9+1XYTnx9zc2CDNRvq4EbAAVc+AZc/andVIiIi+SjcuJnPDbkxBtZ+DHMHQ84JiIyzBg3XuNzuykRERAqkcCNn9vMEmDfY+rpmO+j2PkTG2luTiIjIGWjMjZzZRTdD2ZrWgnx3zFSwERGREk89N27iMw/ONAa2LbZ6aRwOCC8N96+E4DC7KxMRESkU9dy4mVevc5ORCp/fBf93I6yecmq7go2IiHgR9dyIZf9v1myow9sgIAhyMuyuSERE5Jwo3Pg7Y6xBw988CblZEJMA3SdBQgu7KxMRETknCjf+7MRR+PJB2PCl1a7XGa4fCxFlbS1LRETkfCjcuIlXLuJ3YD1snAMBwXD1s3Dp/V4+aEhEREThxu0c3rSMX7XW0PkVqHQxVG5mdzUiIiJuodlS/uT4YZhxFxzafGrbJXcr2IiIiE9Rz42/2L0KZtwJKbutGVH9F+kWlIiI+CSFG1/ndMLKt2Dhs+DMgTI14NrXFWxERMRnKdy4WYnKDOl/w+z7YPMCq31BN+j6BoRF21uXiIiIBync+Kq/t8KUayFtHwSFQcdR0KxvCUtfIiIi7qdw46tKV4XSCRBSCm6eAvEX2l2RiIhIsVC4cZMSsc5N+iEIjYagEAgMhls+hJBICI20uzIREZFio6ngbmbbTZ/tS+Hd1rBwxKltUfEKNiIi4ncUbrydMxeWjIIPr4djybBlIWQdt7sqERER2+i2lDdLS4KZ/a1eG4CL74BOr0BIhL11iYiI2EjhxlttXQQz74H0gxBcCq4dDY1vtbsqERER2yncuImhGEcUnzgKn/WFzBSIvcCaDVWhbvGdX0REpARTuHEzR3GsIxNe2uqp2fGDtX5NcLjnzykiIuIlFG68xeZvISgUalxutS/qbr1EREQkD82WKulys+Hbp+Hj7tYTvY8dsLsiERGREk09N27ikUX8ju62nuS9Z5XVbni9tUifiIiInJbCTUm1cR7Mvh8yjkJoDFz/lhVuRMQr5ebmkp2dbXcZIiVacHAwgYGB5/0+CjcljTMXFjwFP4612pWaQvdJULaGvXWJyDk7duwYe/bswZSI57SIlFwOh4MqVaoQGXl+q+sr3JQ0jgBr7RqASx+AxBHWs6JExCvl5uayZ88eIiIiqFChQvHMqBTxQsYYDh48yJ49e6hTp8559eAo3LjJef8+lpsDgUHgcFjTvBvdAnWudkdpImKj7OxsjDFUqFCB8HAt2yByJhUqVGDHjh1kZ2efV7jRbCk3K/IvZTmZMO9R+KzXqVHJoVEKNiI+Rj02Imfnrr8n6rmx099bYUY/2P+b1d61Eqq1trcmERERL6dwY5c/PocvH4KsNAgvCzeOU7ARERFxA92WKm7ZJ+Crh631a7LSoGoruG8Z1O1gd2UiIiVO9erVGTNmjKvtcDiYPXt2sZz78ssvZ+rUqcVyLn8wf/58mjRpgtPp9Pi5FG7cpNBTPGfcCasnAw5o+z/oMwdiKnu0NhGRourbty8Oh8P1KleuHB07duT333+3ta79+/fTqVMnj5/nyy+/JDk5mVtvvTXf90aOHElgYCCvvPJKvu8988wzNGnSJN/2HTt24HA4WLt2rWubMYb333+fli1bEhkZSenSpWnevDljxozh+PHj51R3RkYGAwYMoFy5ckRGRnLTTTeRnJx8xmOSk5Pp27cvlSpVIiIigo4dO7J58+Z8tRf0mj59umu/n3/+mfbt21O6dGnKlClDhw4d+O2331zf79ixI8HBwXz88cfn9NmKQuHGzc46Fqrt/yCqEtzxObR/2pohJSJSAnXs2JH9+/ezf/9+Fi5cSFBQENdee62tNcXHxxMaGurx87z55pv069ePgID8PyYnTZrEY489xqRJk87rHL169eLhhx/m+uuvZ/Hixaxdu5annnqKL774ggULFpzTez7yyCN89dVXTJ8+ne+//559+/bRrVu30+5vjOGGG25g27ZtfPHFF6xZs4Zq1aqRmJhIeno6AAkJCa4/BydfI0aMIDIy0hU0jx07RseOHalatSo//fQTy5YtIyoqig4dOuRZvLJv3768+eab5/TZisT4mZSUFAOYlJQUt77vrzsPm2qPzzGXvbQw7zcy043Z/kPebdkZbj23iJRcJ06cMOvXrzcnTpwwxhjjdDpNema2LS+n01nouvv06WOuv/76PNt++OEHA5gDBw64tj322GOmTp06Jjw83NSoUcMMGzbMZGVlub6/du1ac+WVV5rIyEgTFRVlmjZtan7++ec873nZZZeZsLAwU6VKFfPggw+aY8eOub5frVo18/rrr7vagJk1a5Yxxpjt27cbwHz++efmyiuvNOHh4aZRo0ZmxYoV+eo+0zn+68CBA8bhcJg//vgj3/eWLFliKleubLKyskylSpXM8uXL83x/+PDhpnHjxvmOO1nrmjVrjDHGfPrppwYws2fPzrev0+k0R48ePW19p3P06FETHBxspk+f7tq2YcMGA5iVK1cWeMymTZsMkOez5ubmmgoVKpjx48ef9lxNmjQxd955p6v9888/G8Ds2rXLte333383gNm8ebNr286dOw1gtmzZUuD7/vfvy78V5ee3ug086cBGmN4XjmyHuxdC/IXW9iDP/9YhIiXTiexcGj79jS3nXv9sByJCzu2f/WPHjvHRRx9Ru3ZtypUr59oeFRXFlClTqFSpEuvWraN///5ERUXx2GOPAXD77bdz8cUX8+677xIYGMjatWsJDg4GYOvWrXTs2JHnn3+eSZMmcfDgQQYOHMjAgQOZPHlyoWsbOnQor776KnXq1GHo0KHcdtttbNmyhaCgoHM6x7Jly4iIiKBBgwb5vjdx4kRuu+02goODue2225g4cSKtWxd9MsjHH39MvXr1uP76/I/VcTgcxMTEuPa79957z/heX3/9NW3btmX16tVkZ2eTmJjo+l79+vWpWrUqK1eu5NJLL813bGZmJgBhYWGubQEBAYSGhrJs2TLuvvvufMesXr2atWvXMnbsWNe2evXqUa5cOSZOnMiTTz5Jbm4uEydOpEGDBlSvXt21X9WqVYmLi+OHH36gVq1aZ/xc56NE3JYaO3Ys1atXJywsjJYtW7Jq1aoz7j99+nTq169PWFgYF110EfPmzSumSk8vz4gbY2DNR/D+lXBwA4TFQGaaTZWJiJybOXPmEBkZSWRkJFFRUXz55Zd8+umneW7VDBs2jNatW1O9enW6du3K4MGD+eyzz1zf37VrF4mJidSvX586depw880307hxY8Aau3L77bfz8MMPU6dOHVq3bs2bb77Jhx9+SEZGRqHrHDx4MF26dKFu3bqMGDGCnTt3smXLlnM+x86dO4mLi8t3Syo1NZUZM2Zwxx13AHDHHXfw2WefcezYsULXetLmzZupV6/eWfe77rrrWLt27RlfzZs3ByApKYmQkBBKly6d5z3i4uJISkoq8P1Php8hQ4Zw5MgRsrKyeOmll9izZw/79+8v8JiToeXfoS4qKoolS5bw0UcfER4eTmRkJPPnz+frr78mKChvoK5UqRI7d+4862c/H7b33Hz66acMGjSIcePG0bJlS8aMGUOHDh3YtGkTsbGx+fZfsWIFt912GyNHjuTaa69l6tSp3HDDDfz6669ceOGFNnyCvCJMBsy6D36fZm2o2Q66vQ+R+T+LiPif8OBA1j9rz+zI8OCirfjarl073n33XQCOHDnCO++8Q6dOnVi1ahXVqlUDrH/D33zzTbZu3cqxY8fIyckhOjra9R6DBg3i7rvv5v/+7/9ITEzk5ptvdv3G/ttvv/H777/nGWBqjMHpdLJ9+/YCe04K0qhRI9fXFStWBODAgQPUr1//nM5x4sSJPD0ZJ33yySfUqlXLFc6aNGlCtWrV+PTTT7nrrrsKVeu/ayiMqKgooqKiivTeRREcHMzMmTO56667KFu2LIGBgSQmJtKpU6cCazxx4gRTp07lqaeeyrf9rrvuok2bNnzyySfk5uby6quv0qVLF37++ec8q3OHh4ef84DpwrK952b06NH079+ffv360bBhQ8aNG0dERMRpB2q98cYbdOzYkUcffZQGDRrw3HPP0bRpU95+++1irjy/+o5dvJ/xqBVsHAFw1TC4Y6aCjYi4OBwOIkKCbHkVdfXXUqVKUbt2bWrXrs0ll1zChAkTSE9PZ/z48QCsXLmS22+/nc6dOzNnzhzWrFnD0KFDycrKcr3HM888w59//kmXLl1YtGgRDRs2ZNasWYB1q+vee+/N0wvx22+/sXnz5iLdsjh5m+vk9QVc043P5Rzly5fnyJEj+bZPnDiRP//8k6CgINdr/fr1eX5eRUdHk5KSku/Yo0ePArhuN9WtW5eNGzee9bN9/PHHrt6z071++OEHwBpsnZWV5TrXScnJycTHx5/2HM2aNWPt2rUcPXqU/fv3M3/+fP7++29q1qyZb98ZM2Zw/PhxevfunWf71KlT2bFjB5MnT+aSSy7h0ksvZerUqWzfvp0vvvgiz76HDx+mQoUKZ/3s58PWnpusrCxWr17NkCFDXNsCAgJITExk5cqVBR6zcuVKBg0alGdbhw4dTrvuQWZmpuueIljdip5ydcAvVDN7IKoi3DQRqrfx2LlERIqbw+EgICCAEydOAFZPerVq1Rg6dKhrn4JuN9StW5e6devyyCOPcNtttzF58mRuvPFGmjZtyvr166ldu7bHaj6Xc1x88cUkJSVx5MgRypQpA8C6dev45ZdfWLJkCWXLlnXte/jwYa688ko2btxI/fr1qVevHnv27CE5OZm4uDjXfr/++ithYWFUrVoVgJ49e3LrrbfyxRdf5Bt3Y4whNTWVmJgYrrvuOlq2bHnGeitXtpYTadasGcHBwSxcuJCbbroJgE2bNrFr1y5atWp11s99Mnht3ryZX375heeeey7fPhMnTuS6667LF06OHz9OQEBAngB9sv3vdW0yMjLYunUrF1988VnrOS9nHXLsQXv37jVAvpHtjz76qGnRokWBxwQHB5upU6fm2TZ27FgTGxtb4P7Dhw83WENi8rw8MVuq/tA55v9euNuYYwfd+t4i4r3ONPujJOvTp4/p2LGj2b9/v9m/f79Zv369eeCBB4zD4TCLFy82xhjzxRdfmKCgIPPJJ5+YLVu2mDfeeMOULVvWxMTEGGOMOX78uBkwYIBZvHix2bFjh1m2bJmpVauWeeyxx4wxxvz2228mPDzcDBgwwKxZs8b89ddfZvbs2WbAgAGuOgozW+rkDCRjjDly5IgBXDUW5hz/lZOTYypUqGC++uor17aHHnrItGzZssD9W7RoYQYPHmyMMSY7O9tccMEFpl27dmb58uVm69atZvr06aZixYrm8ccfdx3jdDpNjx49THh4uHnhhRfMzz//bHbs2GG++uorc9VVV7k+Y1Hdd999pmrVqmbRokXml19+Ma1atTKtWrXKs0+9evXMzJkzXe3PPvvMLF682GzdutXMnj3bVKtWzXTr1i3fe2/evNk4HA7z9ddf5/vehg0bTGhoqLn//vvN+vXrzR9//GHuuOMOExMTY/bt2+fab/HixSYyMtKkp6cXWL+7Zkv5fLjJyMgwKSkprtfu3bs9Em5ERArizeHm378QRkVFmUsuucTMmDEjz36PPvqoKVeunImMjDQ9evQwr7/+uivcZGZmmltvvdUkJCSYkJAQU6lSJTNw4MA812LVqlXm6quvNpGRkaZUqVKmUaNG5oUXXnB9/3zDTWHOUZDHHnvM3Hrrra7PUa5cOfPyyy8XuO9LL71kYmNjXVPg9+7da/r06WOqVq1qwsPDTcOGDc2oUaPyTJE3xppy/e6775pLLrnEREREmOjoaNOsWTPzxhtvmOPHj5+xvtM5ceKEeeCBB0yZMmVMRESEufHGG83+/fvz7AOYyZMnu9pvvPGGqVKligkODjZVq1Y1w4YNM5mZmfnee8iQISYhIcHk5uYWeO4FCxaYNm3amJiYGFOmTBlz1VVX5ZuCfs8995h77733jPW7I9w4/vmgtsjKyiIiIoIZM2Zwww03uLb36dOHo0eP5rtPB9Y0skGDBvHwww+7tg0fPpzZs2fnWQnxdE529aWkpOQZ9CYi4gkZGRls376dGjVqFDhIVUqmpKQkLrjgAn799VfX4Gk5P4cOHaJevXr88ssv1KhRo8B9zvT3pSg/v20dUBwSEkKzZs1YuHCha5vT6WThwoWnvT/YqlWrPPsDfPvtt4W6nygiIlIY8fHxTJw4kV27dtldis/YsWMH77zzzmmDjTvZPhV80KBB9OnTh+bNm9OiRQvGjBlDeno6/fr1A6B3795UrlyZkSNHAvDQQw9xxRVX8Nprr9GlSxemTZvGL7/8wvvvv2/nxxARER/z7zsKcv6aN2/uWpPH02wPNz169ODgwYM8/fTTJCUl0aRJE+bPn+8aZb5r1648Cym1bt2aqVOnMmzYMJ588knq1KnD7NmzS8QaNyIiImI/W8fc2EFjbkSkOGnMjUjh+cSYGxERf+Fnv0eKnBN3/T1RuBER8aDAQOuRB/9etVdECnby78nJvzfnyvYxNyIiviwoKIiIiAgOHjxIcHBwvocxiojF6XRy8OBBIiIi8j1ss6gUbkREPMjhcFCxYkW2b9/u8Schi3i7gIAAqlatWuTnoP2Xwo2IiIeFhIRQp04d3ZoSOYuQkBC39G4q3IiIFIOAgADNlhIpJrr5KyIiIj5F4UZERER8isKNiIiI+BS/G3NzcoGg1NRUmysRERGRwjr5c7swC/35XbhJS0sDICEhweZKREREpKjS0tKIiYk54z5+92wpp9PJvn37iIqKOu959P+VmppKQkICu3fv1nOrPEjXuXjoOhcPXefio2tdPDx1nY0xpKWlUalSpbNOF/e7npuAgACqVKni0XNER0frL04x0HUuHrrOxUPXufjoWhcPT1zns/XYnKQBxSIiIuJTFG5ERETEpyjcuFFoaCjDhw8nNDTU7lJ8mq5z8dB1Lh66zsVH17p4lITr7HcDikVERMS3qedGREREfIrCjYiIiPgUhRsRERHxKQo3IiIi4lMUbopo7NixVK9enbCwMFq2bMmqVavOuP/06dOpX78+YWFhXHTRRcybN6+YKvVuRbnO48ePp23btpQpU4YyZcqQmJh41v8vYinqn+eTpk2bhsPh4IYbbvBsgT6iqNf56NGjDBgwgIoVKxIaGkrdunX1b0chFPU6jxkzhnr16hEeHk5CQgKPPPIIGRkZxVStd1q6dCldu3alUqVKOBwOZs+efdZjlixZQtOmTQkNDaV27dpMmTLF43VipNCmTZtmQkJCzKRJk8yff/5p+vfvb0qXLm2Sk5ML3H/58uUmMDDQvPzyy2b9+vVm2LBhJjg42Kxbt66YK/cuRb3OPXv2NGPHjjVr1qwxGzZsMH379jUxMTFmz549xVy5dynqdT5p+/btpnLlyqZt27bm+uuvL55ivVhRr3NmZqZp3ry56dy5s1m2bJnZvn27WbJkiVm7dm0xV+5dinqdP/74YxMaGmo+/vhjs337dvPNN9+YihUrmkceeaSYK/cu8+bNM0OHDjUzZ840gJk1a9YZ99+2bZuJiIgwgwYNMuvXrzdvvfWWCQwMNPPnz/donQo3RdCiRQszYMAAVzs3N9dUqlTJjBw5ssD9b7nlFtOlS5c821q2bGnuvfdej9bp7Yp6nf8rJyfHREVFmQ8++MBTJfqEc7nOOTk5pnXr1mbChAmmT58+CjeFUNTr/O6775qaNWuarKys4irRJxT1Og8YMMBcddVVebYNGjTItGnTxqN1+pLChJvHHnvMXHDBBXm29ejRw3To0MGDlRmj21KFlJWVxerVq0lMTHRtCwgIIDExkZUrVxZ4zMqVK/PsD9ChQ4fT7i/ndp3/6/jx42RnZ1O2bFlPlen1zvU6P/vss8TGxnLXXXcVR5le71yu85dffkmrVq0YMGAAcXFxXHjhhbz44ovk5uYWV9le51yuc+vWrVm9erXr1tW2bduYN28enTt3Lpaa/YVdPwf97sGZ5+rQoUPk5uYSFxeXZ3tcXBwbN24s8JikpKQC909KSvJYnd7uXK7zfz3++ONUqlQp318oOeVcrvOyZcuYOHEia9euLYYKfcO5XOdt27axaNEibr/9dubNm8eWLVt44IEHyM7OZvjw4cVRttc5l+vcs2dPDh06xGWXXYYxhpycHO677z6efPLJ4ijZb5zu52BqaionTpwgPDzcI+dVz434lFGjRjFt2jRmzZpFWFiY3eX4jLS0NHr16sX48eMpX7683eX4NKfTSWxsLO+//z7NmjWjR48eDB06lHHjxtldmk9ZsmQJL774Iu+88w6//vorM2fOZO7cuTz33HN2lyZuoJ6bQipfvjyBgYEkJyfn2Z6cnEx8fHyBx8THxxdpfzm363zSq6++yqhRo/juu+9o1KiRJ8v0ekW9zlu3bmXHjh107drVtc3pdAIQFBTEpk2bqFWrlmeL9kLn8ue5YsWKBAcHExgY6NrWoEEDkpKSyMrKIiQkxKM1e6Nzuc5PPfUUvXr14u677wbgoosuIj09nXvuuYehQ4cSEKDf/d3hdD8Ho6OjPdZrA+q5KbSQkBCaNWvGwoULXducTicLFy6kVatWBR7TqlWrPPsDfPvtt6fdX87tOgO8/PLLPPfcc8yfP5/mzZsXR6lerajXuX79+qxbt461a9e6Xtdddx3t2rVj7dq1JCQkFGf5XuNc/jy3adOGLVu2uMIjwF9//UXFihUVbE7jXK7z8ePH8wWYk4HS6JGLbmPbz0GPDlf2MdOmTTOhoaFmypQpZv369eaee+4xpUuXNklJScYYY3r16mWeeOIJ1/7Lly83QUFB5tVXXzUbNmwww4cP11TwQijqdR41apQJCQkxM2bMMPv373e90tLS7PoIXqGo1/m/NFuqcIp6nXft2mWioqLMwIEDzaZNm8ycOXNMbGysef755+36CF6hqNd5+PDhJioqynzyySdm27ZtZsGCBaZWrVrmlltusesjeIW0tDSzZs0as2bNGgOY0aNHmzVr1pidO3caY4x54oknTK9evVz7n5wK/uijj5oNGzaYsWPHaip4SfTWW2+ZqlWrmpCQENOiRQvz448/ur53xRVXmD59+uTZ/7PPPjN169Y1ISEh5oILLjBz584t5oq9U1Guc7Vq1QyQ7zV8+PDiL9zLFPXP878p3BReUa/zihUrTMuWLU1oaKipWbOmeeGFF0xOTk4xV+19inKds7OzzTPPPGNq1aplwsLCTEJCgnnggQfMkSNHir9wL7J48eIC/709eW379OljrrjiinzHNGnSxISEhJiaNWuayZMne7xOhzHqfxMRERHfoTE3IiIi4lMUbkRERMSnKNyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfIrCjYiIiPgUhRsRERHxKQo3IlLi9e3bF4fDke+1ZcuWPN8LCQmhdu3aPPvss+Tk5ADW05//fUyFChXo3Lkz69ats/lTiYinKNyIiFfo2LEj+/fvz/OqUaNGnu9t3ryZ//3vfzzzzDO88soreY7ftGkT+/fv55tvviEzM5MuXbqQlZVlx0cREQ9TuBERrxAaGkp8fHye18mnOJ/8XrVq1bj//vtJTEzkyy+/zHN8bGws8fHxNG3alIcffpjdu3ezceNGOz6KiHiYwo2I+Jzw8PDT9sqkpKQwbdo0AEJCQoqzLBEpJkF2FyAiUhhz5swhMjLS1e7UqRPTp0/Ps48xhoULF/LNN9/w4IMP5vlelSpVAEhPTwfguuuuo379+h6uWkTsoHAjIl6hXbt2vPvuu652qVKlXF+fDD7Z2dk4nU569uzJM888k+f4H374gYiICH788UdefPFFxo0bV1yli0gxU7gREa9QqlQpateuXeD3TgafkJAQKlWqRFBQ/n/aatSoQenSpalXrx4HDhygR48eLF261NNli4gNNOZGRLzeyeBTtWrVAoPNfw0YMIA//viDWbNmFUN1IlLcFG5ExO9ERETQv39/hg8fjjHG7nJExM0UbkTELw0cOJANGzbkG5QsIt7PYfRri4iIiPgQ9dyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfIrCjYiIiPgUhRsRERHxKQo3IiIi4lMUbkRERMSnKNyIiIiIT1G4EREREZ+icCMiIiI+ReFGREREfMr/B6OtBQRU88RDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretação dos resultados\n",
        "\n",
        "* **AUC-ROC = 0.9778 (alta)**\n",
        "  O modelo ranqueia muito bem as transações: em média, coloca as fraudes acima das não-fraudes. A curva ROC perto do canto superior-esquerdo confirma isso.\n",
        "* **Recall = 0.9184 (muito alto)**\n",
        "  Ele encontra **90 de 98** fraudes no teste. Só **8** passam batidas (FN).\n",
        "* **Precisão = 0.0585 (muito baixa)**\n",
        "  De cada 100 alertas, **\\~6** são fraudes de verdade. Há **1.448 falsos positivos (FP)** contra **90 verdadeiros positivos (TP)**.\n",
        "  Isso acontece porque a **base é extremamente desbalanceada** (fraude ≈ **0,17%** no teste: 98/56.962). Mesmo um **FPR pequeno (\\~2,55%)** vira muitos FP.\n",
        "* **F1 = 0.1100 (baixo)**\n",
        "  F1 cai porque a precisão é muito baixa (F1 sendo o “meio-termo” entre precisão e recall).\n",
        "* **Acurácia = 0.9744 (enganosa)**\n",
        "  Em bases tão desbalanceadas, como é o caso aqui, acurácia não é útil: um modelo “sempre 0” teria **\\~99,83%** de acurácia aqui — e ainda assim não detectaria nenhuma fraude.\n",
        "\n",
        "## Confusão em números\n",
        "\n",
        "* **TN = 55.416** | **FP = 1.448** → **FPR ≈ 2,55%**\n",
        "* **FN = 8** | **TP = 90** → **Recall ≈ 91,84%**\n",
        "* Só que **Precision = 90 / (90 + 1.448) ≈ 5,85%**\n",
        "\n",
        "## Curvas\n",
        "\n",
        "* **ROC alta**: separabilidade boa (AUC \\~0,978).\n",
        "* **Precision-Recall**: cai conforme se busca mais recall.\n",
        "  No threshold padrão (0,5), o modelo está numa região de **recall alto** com **precisão muito baixa**; subir o threshold pode melhorar a precisão mas diminui recall (trade-off).\n",
        "\n",
        "## Conclusão do baseline\n",
        "\n",
        "* O modelo está bem calibrado para capturar fraudes (recall alto) à custa de muitos falsos positivos, o que dilui a precisão.\n",
        "* Isso não é um erro do modelo, e sim uma consequência do desbalanceamento da base e threshold escolhido.\n"
      ],
      "metadata": {
        "id": "PUWoQMejmzkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Search"
      ],
      "metadata": {
        "id": "WACMfMCypgeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "def _safe_predict_proba_from_pipeline(pipeline, X):\n",
        "    \"\"\"Tenta pipeline.predict_proba; se falhar, aplica preprocess e chama o clf.predict_proba.\"\"\"\n",
        "    try:\n",
        "        proba = pipeline.predict_proba(X)\n",
        "    except Exception:\n",
        "        Xt = pipeline.named_steps[\"preprocess\"].transform(X)\n",
        "        proba = pipeline.named_steps[\"clf\"].predict_proba(Xt)\n",
        "    proba = np.asarray(proba)\n",
        "    return proba[:, 1] if proba.ndim == 2 and proba.shape[1] == 2 else proba.ravel()\n",
        "\n",
        "def safe_auc_scorer(estimator, X, y):\n",
        "    \"\"\"Scorer de AUC robusto para CV com SciKeras + Pipeline.\"\"\"\n",
        "    y_proba = _safe_predict_proba_from_pipeline(estimator, X)\n",
        "    return roc_auc_score(y, y_proba)\n",
        "\n",
        "def stratified_subsample(X, y, max_samples=60000, random_state=42):\n",
        "    \"\"\"Retorna um subset estratificado de até max_samples sem quebrar a proporção das classes.\"\"\"\n",
        "    n = len(y)\n",
        "    if n <= max_samples:\n",
        "        return X, y\n",
        "    frac = max_samples / n\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=frac, random_state=random_state)\n",
        "    idx, _ = next(sss.split(np.zeros(n), y))\n",
        "    return X.iloc[idx], y.iloc[idx]"
      ],
      "metadata": {
        "id": "RACuZ2VGsoRL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import loguniform, randint\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# subset para acelerar a busca (com o dataset inteiro não estava rodando)\n",
        "MAX_SAMPLES_FOR_SEARCH = 60000\n",
        "X_rs, y_rs = stratified_subsample(X_train, y_train, max_samples=MAX_SAMPLES_FOR_SEARCH, random_state=SEED)\n",
        "\n",
        "early_stop_search = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_auc\", patience=2, mode=\"max\", restore_best_weights=True, min_delta=1e-4\n",
        ")\n",
        "reduce_lr_search = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_auc\", factor=0.5, patience=1, mode=\"max\", min_lr=1e-6\n",
        ")\n",
        "\n",
        "# estimador + pipeline\n",
        "base_clf = KerasClassifier(\n",
        "    model=build_mlp,\n",
        "    callbacks=[early_stop_search, reduce_lr_search],\n",
        ")\n",
        "\n",
        "pipe_rs = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", base_clf),\n",
        "])\n",
        "\n",
        "param_distributions = {\n",
        "    \"clf__model__hidden_layers\": randint(1, 4),      # 1..3\n",
        "    \"clf__model__units\": randint(32, 129),           # 32..128\n",
        "    \"clf__model__dropout\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
        "    \"clf__model__l2\": [0.0, 1e-5, 1e-4, 1e-3],\n",
        "    \"clf__model__learning_rate\": loguniform(3e-5, 3e-3),\n",
        "    \"clf__batch_size\": [512, 1024],\n",
        "    \"clf__epochs\": [15, 20],\n",
        "}\n",
        "\n",
        "# CV curto p/ velocidade\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=SEED)\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    estimator=pipe_rs,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=10,\n",
        "    scoring=safe_auc_scorer,\n",
        "    refit=True,\n",
        "    cv=cv,\n",
        "    verbose=1,\n",
        "    n_jobs=1,\n",
        "    random_state=SEED,\n",
        ")\n",
        "\n",
        "rs.fit(X_rs, y_rs, **{**FIT_KW, \"clf__validation_split\": 0.1})\n",
        "\n",
        "print(\"\\n=== Random Search: melhores hiperparâmetros ===\")\n",
        "print(rs.best_params_)\n",
        "print(f\"Melhor AUC-ROC (CV, subset): {rs.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ9BggvTpYlV",
        "outputId": "f436ea5a-5f70-4ad4-db81-d81bce80bd4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 132ms/step - auc: 0.3844 - loss: 1.7655 - prec: 0.0011 - rec: 0.3341 - val_auc: 0.8815 - val_loss: 0.6940 - val_prec: 0.0045 - val_rec: 0.8333 - learning_rate: 0.0011\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - auc: 0.8183 - loss: 0.7068 - prec: 0.0031 - rec: 0.8572 - val_auc: 0.9795 - val_loss: 0.5581 - val_prec: 0.0146 - val_rec: 0.8333 - learning_rate: 0.0011\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.8422 - loss: 0.5657 - prec: 0.0035 - rec: 0.8228 - val_auc: 0.9907 - val_loss: 0.4337 - val_prec: 0.0319 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9165 - loss: 0.4280 - prec: 0.0046 - rec: 0.8837 - val_auc: 0.9937 - val_loss: 0.3324 - val_prec: 0.0531 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9246 - loss: 0.3840 - prec: 0.0056 - rec: 0.8725 - val_auc: 0.9969 - val_loss: 0.2666 - val_prec: 0.0690 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9380 - loss: 0.3417 - prec: 0.0074 - rec: 0.9149 - val_auc: 0.9980 - val_loss: 0.2229 - val_prec: 0.0769 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9577 - loss: 0.2861 - prec: 0.0093 - rec: 0.9162 - val_auc: 0.9985 - val_loss: 0.1901 - val_prec: 0.1053 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9382 - loss: 0.2934 - prec: 0.0111 - rec: 0.9129 - val_auc: 0.9992 - val_loss: 0.1779 - val_prec: 0.0909 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9577 - loss: 0.2505 - prec: 0.0122 - rec: 0.8949 - val_auc: 0.9989 - val_loss: 0.1630 - val_prec: 0.0870 - val_rec: 1.0000 - learning_rate: 0.0011\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9325 - loss: 0.2779 - prec: 0.0136 - rec: 0.9022 - val_auc: 0.9987 - val_loss: 0.1526 - val_prec: 0.0968 - val_rec: 1.0000 - learning_rate: 5.4384e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - auc: 0.4779 - loss: 1.7119 - prec: 0.0017 - rec: 0.5021 - val_auc: 0.9269 - val_loss: 0.6491 - val_prec: 0.0086 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - auc: 0.9040 - loss: 0.5356 - prec: 0.0035 - rec: 0.9070 - val_auc: 0.9348 - val_loss: 0.5362 - val_prec: 0.0222 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9428 - loss: 0.4410 - prec: 0.0045 - rec: 0.9413 - val_auc: 0.9419 - val_loss: 0.4319 - val_prec: 0.0387 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9444 - loss: 0.3869 - prec: 0.0059 - rec: 0.9159 - val_auc: 0.9425 - val_loss: 0.3487 - val_prec: 0.0538 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.8852 - loss: 0.4576 - prec: 0.0067 - rec: 0.8338 - val_auc: 0.9471 - val_loss: 0.2751 - val_prec: 0.0714 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9481 - loss: 0.3231 - prec: 0.0095 - rec: 0.9133 - val_auc: 0.9616 - val_loss: 0.2395 - val_prec: 0.0864 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9821 - loss: 0.2544 - prec: 0.0127 - rec: 0.9807 - val_auc: 0.9557 - val_loss: 0.2130 - val_prec: 0.0909 - val_rec: 0.8750 - learning_rate: 0.0011\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9746 - loss: 0.2448 - prec: 0.0148 - rec: 0.9714 - val_auc: 0.9546 - val_loss: 0.2012 - val_prec: 0.0959 - val_rec: 0.8750 - learning_rate: 5.4384e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - auc: 0.6940 - loss: 0.7588 - prec: 0.0024 - rec: 0.7118 - val_auc: 0.9385 - val_loss: 0.6606 - val_prec: 0.0056 - val_rec: 0.8333 - learning_rate: 2.4867e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.8690 - loss: 0.5199 - prec: 0.0031 - rec: 0.8806 - val_auc: 0.9889 - val_loss: 0.6061 - val_prec: 0.0106 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9199 - loss: 0.4646 - prec: 0.0036 - rec: 0.9198 - val_auc: 0.9961 - val_loss: 0.5592 - val_prec: 0.0132 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9486 - loss: 0.4133 - prec: 0.0040 - rec: 0.9609 - val_auc: 0.9970 - val_loss: 0.5243 - val_prec: 0.0153 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9486 - loss: 0.3941 - prec: 0.0044 - rec: 0.9466 - val_auc: 0.9974 - val_loss: 0.4934 - val_prec: 0.0182 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc: 0.9542 - loss: 0.3822 - prec: 0.0049 - rec: 0.9687 - val_auc: 0.9976 - val_loss: 0.4660 - val_prec: 0.0211 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9575 - loss: 0.3537 - prec: 0.0055 - rec: 0.9592 - val_auc: 0.9980 - val_loss: 0.4435 - val_prec: 0.0238 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.9637 - loss: 0.3334 - prec: 0.0059 - rec: 0.9609 - val_auc: 0.9984 - val_loss: 0.4207 - val_prec: 0.0271 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9481 - loss: 0.3328 - prec: 0.0063 - rec: 0.9208 - val_auc: 0.9987 - val_loss: 0.3953 - val_prec: 0.0326 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9716 - loss: 0.2942 - prec: 0.0074 - rec: 0.9725 - val_auc: 0.9988 - val_loss: 0.3728 - val_prec: 0.0397 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9604 - loss: 0.2946 - prec: 0.0081 - rec: 0.9492 - val_auc: 0.9989 - val_loss: 0.3624 - val_prec: 0.0420 - val_rec: 1.0000 - learning_rate: 1.2433e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9598 - loss: 0.2971 - prec: 0.0083 - rec: 0.9297 - val_auc: 0.9990 - val_loss: 0.3524 - val_prec: 0.0438 - val_rec: 1.0000 - learning_rate: 1.2433e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9755 - loss: 0.2649 - prec: 0.0091 - rec: 0.9725 - val_auc: 0.9991 - val_loss: 0.3476 - val_prec: 0.0451 - val_rec: 1.0000 - learning_rate: 6.2167e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9740 - loss: 0.2677 - prec: 0.0093 - rec: 0.9725 - val_auc: 0.9991 - val_loss: 0.3433 - val_prec: 0.0465 - val_rec: 1.0000 - learning_rate: 6.2167e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9737 - loss: 0.2622 - prec: 0.0098 - rec: 0.9725 - val_auc: 0.9991 - val_loss: 0.3404 - val_prec: 0.0472 - val_rec: 1.0000 - learning_rate: 3.1083e-05\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - auc: 0.6951 - loss: 1.0436 - prec: 0.0028 - rec: 0.7510 - val_auc: 0.9811 - val_loss: 0.7158 - val_prec: 0.0061 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - auc: 0.7936 - loss: 0.6566 - prec: 0.0030 - rec: 0.7736 - val_auc: 0.9895 - val_loss: 0.6878 - val_prec: 0.0081 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9427 - loss: 0.4718 - prec: 0.0040 - rec: 0.9733 - val_auc: 0.9916 - val_loss: 0.6538 - val_prec: 0.0097 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9455 - loss: 0.4465 - prec: 0.0042 - rec: 0.9462 - val_auc: 0.9934 - val_loss: 0.6133 - val_prec: 0.0115 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9355 - loss: 0.4917 - prec: 0.0046 - rec: 0.9467 - val_auc: 0.9939 - val_loss: 0.5806 - val_prec: 0.0136 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9784 - loss: 0.3836 - prec: 0.0053 - rec: 1.0000 - val_auc: 0.9946 - val_loss: 0.5555 - val_prec: 0.0150 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9650 - loss: 0.3768 - prec: 0.0056 - rec: 0.9620 - val_auc: 0.9946 - val_loss: 0.5194 - val_prec: 0.0173 - val_rec: 1.0000 - learning_rate: 2.4867e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9647 - loss: 0.3632 - prec: 0.0061 - rec: 0.9600 - val_auc: 0.9949 - val_loss: 0.5110 - val_prec: 0.0177 - val_rec: 1.0000 - learning_rate: 1.2433e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9651 - loss: 0.3601 - prec: 0.0065 - rec: 0.9613 - val_auc: 0.9949 - val_loss: 0.4981 - val_prec: 0.0188 - val_rec: 1.0000 - learning_rate: 1.2433e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9728 - loss: 0.3431 - prec: 0.0066 - rec: 0.9679 - val_auc: 0.9950 - val_loss: 0.4934 - val_prec: 0.0193 - val_rec: 1.0000 - learning_rate: 6.2167e-05\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - auc: 0.6499 - loss: 0.9385 - prec: 0.0022 - rec: 0.6859 - val_auc: 0.8444 - val_loss: 0.6522 - val_prec: 0.0119 - val_rec: 0.8333 - learning_rate: 0.0014\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - auc: 0.8993 - loss: 0.5446 - prec: 0.0042 - rec: 0.8958 - val_auc: 0.9936 - val_loss: 0.5032 - val_prec: 0.0395 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9152 - loss: 0.4656 - prec: 0.0063 - rec: 0.8812 - val_auc: 0.9963 - val_loss: 0.3795 - val_prec: 0.0732 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9560 - loss: 0.3631 - prec: 0.0098 - rec: 0.9388 - val_auc: 0.9992 - val_loss: 0.3180 - val_prec: 0.0896 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9731 - loss: 0.2917 - prec: 0.0146 - rec: 0.9725 - val_auc: 0.9993 - val_loss: 0.2709 - val_prec: 0.1176 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9722 - loss: 0.2716 - prec: 0.0202 - rec: 0.9656 - val_auc: 0.9999 - val_loss: 0.2388 - val_prec: 0.1277 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9726 - loss: 0.2522 - prec: 0.0258 - rec: 0.9725 - val_auc: 1.0000 - val_loss: 0.2161 - val_prec: 0.1364 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9778 - loss: 0.2121 - prec: 0.0333 - rec: 0.9725 - val_auc: 1.0000 - val_loss: 0.2009 - val_prec: 0.1765 - val_rec: 1.0000 - learning_rate: 6.9339e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9667 - loss: 0.2419 - prec: 0.0372 - rec: 0.9698 - val_auc: 1.0000 - val_loss: 0.1922 - val_prec: 0.1579 - val_rec: 1.0000 - learning_rate: 6.9339e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9750 - loss: 0.2090 - prec: 0.0382 - rec: 0.9725 - val_auc: 0.9999 - val_loss: 0.1898 - val_prec: 0.1538 - val_rec: 1.0000 - learning_rate: 3.4669e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - auc: 0.5339 - loss: 1.2115 - prec: 0.0017 - rec: 0.4931 - val_auc: 0.9937 - val_loss: 0.7317 - val_prec: 0.0100 - val_rec: 1.0000 - learning_rate: 0.0014\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - auc: 0.9568 - loss: 0.5361 - prec: 0.0044 - rec: 0.9704 - val_auc: 0.9883 - val_loss: 0.5369 - val_prec: 0.0417 - val_rec: 0.8750 - learning_rate: 0.0014\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9395 - loss: 0.4787 - prec: 0.0058 - rec: 0.8994 - val_auc: 0.9843 - val_loss: 0.4778 - val_prec: 0.0530 - val_rec: 0.8750 - learning_rate: 6.9339e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 183ms/step - auc: 0.4844 - loss: 1.4223 - prec: 0.0014 - rec: 0.4876 - val_auc: 0.4705 - val_loss: 0.5385 - val_prec: 0.0047 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - auc: 0.4885 - loss: 1.2971 - prec: 0.0014 - rec: 0.4740 - val_auc: 0.5020 - val_loss: 0.5737 - val_prec: 0.0035 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - auc: 0.6101 - loss: 1.3381 - prec: 0.0018 - rec: 0.6097 - val_auc: 0.5043 - val_loss: 0.6042 - val_prec: 0.0029 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc: 0.6183 - loss: 1.0279 - prec: 0.0018 - rec: 0.5927 - val_auc: 0.5066 - val_loss: 0.6300 - val_prec: 0.0026 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.7780 - loss: 0.7346 - prec: 0.0024 - rec: 0.8152 - val_auc: 0.5088 - val_loss: 0.6511 - val_prec: 0.0024 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.7520 - loss: 0.7343 - prec: 0.0022 - rec: 0.7416 - val_auc: 0.5122 - val_loss: 0.6677 - val_prec: 0.0023 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.5696 - loss: 1.1281 - prec: 0.0017 - rec: 0.5449 - val_auc: 0.5218 - val_loss: 0.6802 - val_prec: 0.0023 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.6859 - loss: 0.8308 - prec: 0.0021 - rec: 0.6777 - val_auc: 0.5376 - val_loss: 0.6894 - val_prec: 0.0022 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.7898 - loss: 0.7723 - prec: 0.0024 - rec: 0.7992 - val_auc: 0.5521 - val_loss: 0.6951 - val_prec: 0.0022 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.7516 - loss: 0.7795 - prec: 0.0024 - rec: 0.7831 - val_auc: 0.5805 - val_loss: 0.6972 - val_prec: 0.0022 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8775 - loss: 0.5847 - prec: 0.0028 - rec: 0.8947 - val_auc: 0.6088 - val_loss: 0.6969 - val_prec: 0.0023 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.7779 - loss: 0.6983 - prec: 0.0025 - rec: 0.7690 - val_auc: 0.6386 - val_loss: 0.6944 - val_prec: 0.0023 - val_rec: 0.5000 - learning_rate: 1.2179e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.7743 - loss: 0.6348 - prec: 0.0027 - rec: 0.8111 - val_auc: 0.6887 - val_loss: 0.6899 - val_prec: 0.0031 - val_rec: 0.6667 - learning_rate: 1.2179e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8637 - loss: 0.5397 - prec: 0.0028 - rec: 0.8569 - val_auc: 0.7315 - val_loss: 0.6840 - val_prec: 0.0039 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.8999 - loss: 0.5147 - prec: 0.0030 - rec: 0.9032 - val_auc: 0.7492 - val_loss: 0.6774 - val_prec: 0.0040 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8653 - loss: 0.5937 - prec: 0.0030 - rec: 0.8724 - val_auc: 0.7760 - val_loss: 0.6699 - val_prec: 0.0041 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8629 - loss: 0.5036 - prec: 0.0029 - rec: 0.8149 - val_auc: 0.8033 - val_loss: 0.6615 - val_prec: 0.0042 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9164 - loss: 0.4949 - prec: 0.0033 - rec: 0.9266 - val_auc: 0.8119 - val_loss: 0.6526 - val_prec: 0.0043 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8742 - loss: 0.5248 - prec: 0.0031 - rec: 0.8596 - val_auc: 0.8231 - val_loss: 0.6427 - val_prec: 0.0044 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9123 - loss: 0.4790 - prec: 0.0034 - rec: 0.9101 - val_auc: 0.8339 - val_loss: 0.6329 - val_prec: 0.0045 - val_rec: 0.8333 - learning_rate: 1.2179e-04\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 188ms/step - auc: 0.4299 - loss: 1.4449 - prec: 0.0015 - rec: 0.4780 - val_auc: 0.6668 - val_loss: 0.7211 - val_prec: 0.0035 - val_rec: 0.6250 - learning_rate: 1.2179e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.5223 - loss: 1.4375 - prec: 0.0016 - rec: 0.5113 - val_auc: 0.7282 - val_loss: 0.7297 - val_prec: 0.0034 - val_rec: 0.6250 - learning_rate: 1.2179e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.5648 - loss: 1.0927 - prec: 0.0018 - rec: 0.5398 - val_auc: 0.8048 - val_loss: 0.7374 - val_prec: 0.0048 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.5822 - loss: 0.9576 - prec: 0.0019 - rec: 0.5746 - val_auc: 0.8428 - val_loss: 0.7445 - val_prec: 0.0048 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.5492 - loss: 1.0230 - prec: 0.0015 - rec: 0.4653 - val_auc: 0.8582 - val_loss: 0.7498 - val_prec: 0.0048 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.7238 - loss: 0.7437 - prec: 0.0023 - rec: 0.6785 - val_auc: 0.8648 - val_loss: 0.7522 - val_prec: 0.0048 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.7572 - loss: 0.6468 - prec: 0.0025 - rec: 0.7376 - val_auc: 0.8722 - val_loss: 0.7524 - val_prec: 0.0048 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8149 - loss: 0.6361 - prec: 0.0028 - rec: 0.8347 - val_auc: 0.8759 - val_loss: 0.7505 - val_prec: 0.0049 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8767 - loss: 0.5324 - prec: 0.0031 - rec: 0.8975 - val_auc: 0.8778 - val_loss: 0.7461 - val_prec: 0.0050 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8925 - loss: 0.5198 - prec: 0.0031 - rec: 0.8970 - val_auc: 0.8801 - val_loss: 0.7402 - val_prec: 0.0051 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8257 - loss: 0.5547 - prec: 0.0028 - rec: 0.7856 - val_auc: 0.8835 - val_loss: 0.7330 - val_prec: 0.0052 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8136 - loss: 0.5596 - prec: 0.0031 - rec: 0.8474 - val_auc: 0.8857 - val_loss: 0.7253 - val_prec: 0.0054 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9024 - loss: 0.4998 - prec: 0.0034 - rec: 0.9219 - val_auc: 0.8862 - val_loss: 0.7167 - val_prec: 0.0055 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8560 - loss: 0.5254 - prec: 0.0031 - rec: 0.8387 - val_auc: 0.8867 - val_loss: 0.7072 - val_prec: 0.0056 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9151 - loss: 0.4679 - prec: 0.0034 - rec: 0.9020 - val_auc: 0.8877 - val_loss: 0.6973 - val_prec: 0.0058 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8927 - loss: 0.5191 - prec: 0.0035 - rec: 0.8918 - val_auc: 0.8875 - val_loss: 0.6865 - val_prec: 0.0058 - val_rec: 0.8750 - learning_rate: 1.2179e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9351 - loss: 0.4522 - prec: 0.0037 - rec: 0.9295 - val_auc: 0.8878 - val_loss: 0.6824 - val_prec: 0.0059 - val_rec: 0.8750 - learning_rate: 6.0894e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9284 - loss: 0.4514 - prec: 0.0037 - rec: 0.9354 - val_auc: 0.8871 - val_loss: 0.6777 - val_prec: 0.0059 - val_rec: 0.8750 - learning_rate: 6.0894e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9165 - loss: 0.4556 - prec: 0.0036 - rec: 0.9114 - val_auc: 0.8872 - val_loss: 0.6762 - val_prec: 0.0060 - val_rec: 0.8750 - learning_rate: 3.0447e-05\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 93ms/step - auc: 0.8371 - loss: 0.5838 - prec: 0.0029 - rec: 0.8685 - val_auc: 0.7607 - val_loss: 0.6295 - val_prec: 0.0043 - val_rec: 0.6667 - learning_rate: 5.0214e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - auc: 0.9403 - loss: 0.3849 - prec: 0.0042 - rec: 0.9244 - val_auc: 0.8516 - val_loss: 0.5141 - val_prec: 0.0102 - val_rec: 0.8333 - learning_rate: 5.0214e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9604 - loss: 0.3016 - prec: 0.0066 - rec: 0.9609 - val_auc: 0.9874 - val_loss: 0.4244 - val_prec: 0.0239 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9726 - loss: 0.2461 - prec: 0.0109 - rec: 0.9609 - val_auc: 0.9973 - val_loss: 0.3537 - val_prec: 0.0417 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9771 - loss: 0.2043 - prec: 0.0180 - rec: 0.9725 - val_auc: 0.9993 - val_loss: 0.2965 - val_prec: 0.0606 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9791 - loss: 0.1720 - prec: 0.0287 - rec: 0.9725 - val_auc: 0.9999 - val_loss: 0.2504 - val_prec: 0.0800 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9801 - loss: 0.1467 - prec: 0.0418 - rec: 0.9725 - val_auc: 1.0000 - val_loss: 0.2133 - val_prec: 0.1053 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9806 - loss: 0.1284 - prec: 0.0535 - rec: 0.9725 - val_auc: 1.0000 - val_loss: 0.1982 - val_prec: 0.1132 - val_rec: 1.0000 - learning_rate: 2.5107e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9807 - loss: 0.1195 - prec: 0.0590 - rec: 0.9725 - val_auc: 1.0000 - val_loss: 0.1842 - val_prec: 0.1200 - val_rec: 1.0000 - learning_rate: 2.5107e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9808 - loss: 0.1122 - prec: 0.0640 - rec: 0.9725 - val_auc: 1.0000 - val_loss: 0.1777 - val_prec: 0.1250 - val_rec: 1.0000 - learning_rate: 1.2554e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - auc: 0.7233 - loss: 0.6987 - prec: 0.0025 - rec: 0.7122 - val_auc: 0.9535 - val_loss: 0.5938 - val_prec: 0.0086 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - auc: 0.9702 - loss: 0.3921 - prec: 0.0042 - rec: 0.9565 - val_auc: 0.9674 - val_loss: 0.5090 - val_prec: 0.0135 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9846 - loss: 0.3203 - prec: 0.0063 - rec: 0.9886 - val_auc: 0.9765 - val_loss: 0.4349 - val_prec: 0.0200 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9923 - loss: 0.2641 - prec: 0.0100 - rec: 1.0000 - val_auc: 0.9819 - val_loss: 0.3719 - val_prec: 0.0318 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9963 - loss: 0.2200 - prec: 0.0166 - rec: 1.0000 - val_auc: 0.9854 - val_loss: 0.3183 - val_prec: 0.0449 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9980 - loss: 0.1850 - prec: 0.0266 - rec: 1.0000 - val_auc: 0.9888 - val_loss: 0.2732 - val_prec: 0.0642 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9989 - loss: 0.1569 - prec: 0.0395 - rec: 1.0000 - val_auc: 0.9904 - val_loss: 0.2351 - val_prec: 0.0814 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9993 - loss: 0.1340 - prec: 0.0547 - rec: 1.0000 - val_auc: 0.9913 - val_loss: 0.2028 - val_prec: 0.0986 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9995 - loss: 0.1153 - prec: 0.0733 - rec: 1.0000 - val_auc: 0.9925 - val_loss: 0.1766 - val_prec: 0.1167 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9996 - loss: 0.1001 - prec: 0.0919 - rec: 1.0000 - val_auc: 0.9929 - val_loss: 0.1544 - val_prec: 0.1296 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9997 - loss: 0.0874 - prec: 0.1142 - rec: 1.0000 - val_auc: 0.9933 - val_loss: 0.1356 - val_prec: 0.1489 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9997 - loss: 0.0769 - prec: 0.1311 - rec: 1.0000 - val_auc: 0.9938 - val_loss: 0.1203 - val_prec: 0.1842 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9998 - loss: 0.0681 - prec: 0.1520 - rec: 1.0000 - val_auc: 0.9941 - val_loss: 0.1071 - val_prec: 0.1944 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9998 - loss: 0.0606 - prec: 0.1750 - rec: 1.0000 - val_auc: 0.9944 - val_loss: 0.0959 - val_prec: 0.2059 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9998 - loss: 0.0543 - prec: 0.1972 - rec: 1.0000 - val_auc: 0.9945 - val_loss: 0.0869 - val_prec: 0.2188 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9999 - loss: 0.0489 - prec: 0.2130 - rec: 1.0000 - val_auc: 0.9947 - val_loss: 0.0787 - val_prec: 0.2333 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9999 - loss: 0.0444 - prec: 0.2266 - rec: 1.0000 - val_auc: 0.9949 - val_loss: 0.0720 - val_prec: 0.2593 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9999 - loss: 0.0405 - prec: 0.2412 - rec: 1.0000 - val_auc: 0.9949 - val_loss: 0.0664 - val_prec: 0.2692 - val_rec: 0.8750 - learning_rate: 5.0214e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9999 - loss: 0.0373 - prec: 0.2562 - rec: 1.0000 - val_auc: 0.9951 - val_loss: 0.0639 - val_prec: 0.2692 - val_rec: 0.8750 - learning_rate: 2.5107e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9999 - loss: 0.0357 - prec: 0.2600 - rec: 1.0000 - val_auc: 0.9952 - val_loss: 0.0614 - val_prec: 0.2800 - val_rec: 0.8750 - learning_rate: 2.5107e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 247ms/step - auc: 0.4860 - loss: 1.3604 - prec: 0.0014 - rec: 0.4494 - val_auc: 0.9561 - val_loss: 0.7176 - val_prec: 0.0032 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - auc: 0.7646 - loss: 0.6836 - prec: 0.0022 - rec: 0.7324 - val_auc: 0.9797 - val_loss: 0.7642 - val_prec: 0.0027 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - auc: 0.6491 - loss: 1.0294 - prec: 0.0020 - rec: 0.6584 - val_auc: 0.9861 - val_loss: 0.7961 - val_prec: 0.0026 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - auc: 0.6880 - loss: 0.8066 - prec: 0.0020 - rec: 0.6461 - val_auc: 0.9892 - val_loss: 0.8123 - val_prec: 0.0027 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - auc: 0.8256 - loss: 0.6303 - prec: 0.0026 - rec: 0.8395 - val_auc: 0.9911 - val_loss: 0.8193 - val_prec: 0.0027 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8456 - loss: 0.6280 - prec: 0.0026 - rec: 0.8552 - val_auc: 0.9930 - val_loss: 0.8179 - val_prec: 0.0029 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9013 - loss: 0.5192 - prec: 0.0028 - rec: 0.8998 - val_auc: 0.9947 - val_loss: 0.8123 - val_prec: 0.0030 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8032 - loss: 1.0831 - prec: 0.0026 - rec: 0.8192 - val_auc: 0.9951 - val_loss: 0.8009 - val_prec: 0.0032 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8955 - loss: 0.6368 - prec: 0.0030 - rec: 0.9271 - val_auc: 0.9957 - val_loss: 0.7905 - val_prec: 0.0034 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8564 - loss: 0.5685 - prec: 0.0027 - rec: 0.8259 - val_auc: 0.9964 - val_loss: 0.7820 - val_prec: 0.0035 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9140 - loss: 0.5615 - prec: 0.0031 - rec: 0.9365 - val_auc: 0.9968 - val_loss: 0.7746 - val_prec: 0.0036 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9094 - loss: 0.5095 - prec: 0.0031 - rec: 0.9355 - val_auc: 0.9971 - val_loss: 0.7661 - val_prec: 0.0037 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9523 - loss: 0.4581 - prec: 0.0032 - rec: 0.9714 - val_auc: 0.9973 - val_loss: 0.7589 - val_prec: 0.0038 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9206 - loss: 0.5260 - prec: 0.0031 - rec: 0.9220 - val_auc: 0.9975 - val_loss: 0.7484 - val_prec: 0.0040 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9699 - loss: 0.4514 - prec: 0.0034 - rec: 0.9814 - val_auc: 0.9976 - val_loss: 0.7375 - val_prec: 0.0041 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9472 - loss: 0.4501 - prec: 0.0034 - rec: 0.9649 - val_auc: 0.9980 - val_loss: 0.7277 - val_prec: 0.0042 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9291 - loss: 0.4789 - prec: 0.0033 - rec: 0.9451 - val_auc: 0.9983 - val_loss: 0.7200 - val_prec: 0.0043 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.9510 - loss: 0.4535 - prec: 0.0033 - rec: 0.9430 - val_auc: 0.9984 - val_loss: 0.7127 - val_prec: 0.0044 - val_rec: 1.0000 - learning_rate: 4.5534e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.8879 - loss: 0.5457 - prec: 0.0033 - rec: 0.9159 - val_auc: 0.9985 - val_loss: 0.7087 - val_prec: 0.0045 - val_rec: 1.0000 - learning_rate: 2.2767e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.9521 - loss: 0.4372 - prec: 0.0034 - rec: 0.9461 - val_auc: 0.9986 - val_loss: 0.7062 - val_prec: 0.0045 - val_rec: 1.0000 - learning_rate: 2.2767e-05\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 247ms/step - auc: 0.3365 - loss: 1.8263 - prec: 0.0011 - rec: 0.3484 - val_auc: 0.5567 - val_loss: 0.6373 - val_prec: 0.0047 - val_rec: 0.5000 - learning_rate: 4.5534e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.4991 - loss: 1.8234 - prec: 0.0017 - rec: 0.5322 - val_auc: 0.6299 - val_loss: 0.6939 - val_prec: 0.0032 - val_rec: 0.6250 - learning_rate: 4.5534e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.5629 - loss: 1.6707 - prec: 0.0019 - rec: 0.6152 - val_auc: 0.7713 - val_loss: 0.7397 - val_prec: 0.0032 - val_rec: 0.7500 - learning_rate: 4.5534e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.4655 - loss: 1.7582 - prec: 0.0014 - rec: 0.4398 - val_auc: 0.7741 - val_loss: 0.7715 - val_prec: 0.0030 - val_rec: 0.7500 - learning_rate: 4.5534e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.6956 - loss: 1.4111 - prec: 0.0024 - rec: 0.7267 - val_auc: 0.7725 - val_loss: 0.7932 - val_prec: 0.0030 - val_rec: 0.7500 - learning_rate: 4.5534e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.7681 - loss: 0.8811 - prec: 0.0026 - rec: 0.7850 - val_auc: 0.7714 - val_loss: 0.8127 - val_prec: 0.0030 - val_rec: 0.7500 - learning_rate: 2.2767e-05\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - auc: 0.6474 - loss: 0.8495 - prec: 0.0022 - rec: 0.6666 - val_auc: 0.8394 - val_loss: 0.6413 - val_prec: 0.0050 - val_rec: 0.8333 - learning_rate: 0.0016\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9345 - loss: 0.3987 - prec: 0.0041 - rec: 0.9334 - val_auc: 0.9079 - val_loss: 0.4959 - val_prec: 0.0120 - val_rec: 0.8333 - learning_rate: 0.0016\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9477 - loss: 0.3275 - prec: 0.0063 - rec: 0.9567 - val_auc: 0.9648 - val_loss: 0.3785 - val_prec: 0.0273 - val_rec: 0.8333 - learning_rate: 0.0016\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9397 - loss: 0.2809 - prec: 0.0089 - rec: 0.9049 - val_auc: 0.9955 - val_loss: 0.2931 - val_prec: 0.0659 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 5/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9681 - loss: 0.2050 - prec: 0.0158 - rec: 0.9544 - val_auc: 0.9967 - val_loss: 0.2260 - val_prec: 0.0877 - val_rec: 0.8333 - learning_rate: 0.0016\n",
            "Epoch 6/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9619 - loss: 0.1817 - prec: 0.0228 - rec: 0.9450 - val_auc: 0.9989 - val_loss: 0.1855 - val_prec: 0.1395 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 7/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9733 - loss: 0.1576 - prec: 0.0303 - rec: 0.9592 - val_auc: 0.9996 - val_loss: 0.1596 - val_prec: 0.1500 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 8/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9793 - loss: 0.1239 - prec: 0.0354 - rec: 0.9725 - val_auc: 0.9997 - val_loss: 0.1327 - val_prec: 0.1875 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 9/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9801 - loss: 0.1022 - prec: 0.0496 - rec: 0.9815 - val_auc: 0.9997 - val_loss: 0.1091 - val_prec: 0.2500 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 10/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9805 - loss: 0.0880 - prec: 0.0573 - rec: 0.9709 - val_auc: 0.9997 - val_loss: 0.1004 - val_prec: 0.2500 - val_rec: 1.0000 - learning_rate: 7.8700e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 89ms/step - auc: 0.8573 - loss: 0.7391 - prec: 0.0037 - rec: 0.8940 - val_auc: 0.9968 - val_loss: 0.5619 - val_prec: 0.0161 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 2/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - auc: 0.9590 - loss: 0.3598 - prec: 0.0065 - rec: 0.9374 - val_auc: 0.9970 - val_loss: 0.3895 - val_prec: 0.0376 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 3/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9671 - loss: 0.2671 - prec: 0.0115 - rec: 0.9506 - val_auc: 0.9969 - val_loss: 0.2888 - val_prec: 0.0615 - val_rec: 1.0000 - learning_rate: 0.0016\n",
            "Epoch 4/20\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9768 - loss: 0.2142 - prec: 0.0175 - rec: 0.9679 - val_auc: 0.9968 - val_loss: 0.2571 - val_prec: 0.0667 - val_rec: 1.0000 - learning_rate: 7.8700e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - auc: 0.5774 - loss: 1.1355 - prec: 0.0015 - rec: 0.5118 - val_auc: 0.6702 - val_loss: 0.7121 - val_prec: 0.0023 - val_rec: 0.5000 - learning_rate: 4.0151e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.8131 - loss: 0.6318 - prec: 0.0025 - rec: 0.7922 - val_auc: 0.9938 - val_loss: 0.6904 - val_prec: 0.0049 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9120 - loss: 0.4902 - prec: 0.0031 - rec: 0.9021 - val_auc: 0.9995 - val_loss: 0.6531 - val_prec: 0.0056 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9059 - loss: 0.5086 - prec: 0.0035 - rec: 0.8939 - val_auc: 0.9997 - val_loss: 0.6101 - val_prec: 0.0067 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9508 - loss: 0.3876 - prec: 0.0043 - rec: 0.9583 - val_auc: 0.9997 - val_loss: 0.5650 - val_prec: 0.0080 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9624 - loss: 0.3489 - prec: 0.0051 - rec: 0.9567 - val_auc: 0.9997 - val_loss: 0.5455 - val_prec: 0.0087 - val_rec: 1.0000 - learning_rate: 2.0076e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Epoch 1/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 96ms/step - auc: 0.5523 - loss: 0.9345 - prec: 0.0019 - rec: 0.5473 - val_auc: 0.7777 - val_loss: 0.7612 - val_prec: 0.0044 - val_rec: 0.7500 - learning_rate: 4.0151e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - auc: 0.8404 - loss: 0.5962 - prec: 0.0030 - rec: 0.8279 - val_auc: 0.8998 - val_loss: 0.7159 - val_prec: 0.0061 - val_rec: 0.8750 - learning_rate: 4.0151e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9573 - loss: 0.4542 - prec: 0.0040 - rec: 0.9733 - val_auc: 0.9589 - val_loss: 0.6685 - val_prec: 0.0082 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9668 - loss: 0.4138 - prec: 0.0047 - rec: 0.9641 - val_auc: 0.9745 - val_loss: 0.6229 - val_prec: 0.0100 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9505 - loss: 0.4061 - prec: 0.0051 - rec: 0.8849 - val_auc: 0.9840 - val_loss: 0.5787 - val_prec: 0.0122 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9813 - loss: 0.3493 - prec: 0.0068 - rec: 0.9620 - val_auc: 0.9866 - val_loss: 0.5359 - val_prec: 0.0150 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9907 - loss: 0.3204 - prec: 0.0086 - rec: 1.0000 - val_auc: 0.9884 - val_loss: 0.4948 - val_prec: 0.0190 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9792 - loss: 0.3082 - prec: 0.0101 - rec: 0.9413 - val_auc: 0.9891 - val_loss: 0.4565 - val_prec: 0.0240 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9829 - loss: 0.2909 - prec: 0.0127 - rec: 0.9571 - val_auc: 0.9908 - val_loss: 0.4208 - val_prec: 0.0305 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9884 - loss: 0.2666 - prec: 0.0150 - rec: 0.9571 - val_auc: 0.9911 - val_loss: 0.3899 - val_prec: 0.0374 - val_rec: 1.0000 - learning_rate: 4.0151e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9938 - loss: 0.2426 - prec: 0.0194 - rec: 0.9886 - val_auc: 0.9920 - val_loss: 0.3604 - val_prec: 0.0391 - val_rec: 0.8750 - learning_rate: 4.0151e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9847 - loss: 0.2464 - prec: 0.0220 - rec: 0.9480 - val_auc: 0.9927 - val_loss: 0.3355 - val_prec: 0.0467 - val_rec: 0.8750 - learning_rate: 4.0151e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9933 - loss: 0.2278 - prec: 0.0269 - rec: 0.9679 - val_auc: 0.9926 - val_loss: 0.3115 - val_prec: 0.0534 - val_rec: 0.8750 - learning_rate: 4.0151e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9950 - loss: 0.2091 - prec: 0.0274 - rec: 0.9413 - val_auc: 0.9924 - val_loss: 0.3014 - val_prec: 0.0583 - val_rec: 0.8750 - learning_rate: 2.0076e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 247ms/step - auc: 0.2656 - loss: 2.3133 - prec: 6.9400e-04 - rec: 0.2235 - val_auc: 0.4944 - val_loss: 0.7865 - val_prec: 0.0024 - val_rec: 0.5000 - learning_rate: 5.2626e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.2433 - loss: 2.0560 - prec: 7.5562e-04 - rec: 0.2424 - val_auc: 0.5013 - val_loss: 0.8228 - val_prec: 0.0019 - val_rec: 0.5000 - learning_rate: 5.2626e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.3289 - loss: 1.8861 - prec: 0.0010 - rec: 0.3438 - val_auc: 0.5171 - val_loss: 0.8546 - val_prec: 0.0017 - val_rec: 0.5000 - learning_rate: 5.2626e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.4026 - loss: 1.3711 - prec: 0.0014 - rec: 0.4628 - val_auc: 0.5487 - val_loss: 0.8810 - val_prec: 0.0017 - val_rec: 0.5000 - learning_rate: 5.2626e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.4462 - loss: 1.4539 - prec: 0.0016 - rec: 0.5304 - val_auc: 0.6003 - val_loss: 0.9017 - val_prec: 0.0022 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - auc: 0.4918 - loss: 1.3232 - prec: 0.0018 - rec: 0.5623 - val_auc: 0.6426 - val_loss: 0.9166 - val_prec: 0.0023 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - auc: 0.6164 - loss: 0.9873 - prec: 0.0021 - rec: 0.6942 - val_auc: 0.6606 - val_loss: 0.9258 - val_prec: 0.0023 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - auc: 0.5357 - loss: 1.0826 - prec: 0.0018 - rec: 0.5641 - val_auc: 0.6719 - val_loss: 0.9339 - val_prec: 0.0023 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - auc: 0.5496 - loss: 1.1942 - prec: 0.0019 - rec: 0.6202 - val_auc: 0.6917 - val_loss: 0.9388 - val_prec: 0.0024 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - auc: 0.6393 - loss: 0.8709 - prec: 0.0021 - rec: 0.6850 - val_auc: 0.7258 - val_loss: 0.9418 - val_prec: 0.0024 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - auc: 0.6773 - loss: 0.9409 - prec: 0.0022 - rec: 0.6978 - val_auc: 0.7809 - val_loss: 0.9415 - val_prec: 0.0025 - val_rec: 0.6667 - learning_rate: 5.2626e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - auc: 0.6966 - loss: 0.8259 - prec: 0.0026 - rec: 0.8314 - val_auc: 0.8338 - val_loss: 0.9406 - val_prec: 0.0031 - val_rec: 0.8333 - learning_rate: 5.2626e-05\n",
            "Epoch 13/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - auc: 0.6654 - loss: 0.9286 - prec: 0.0022 - rec: 0.7001 - val_auc: 0.8736 - val_loss: 0.9393 - val_prec: 0.0038 - val_rec: 1.0000 - learning_rate: 5.2626e-05\n",
            "Epoch 14/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - auc: 0.7447 - loss: 0.8791 - prec: 0.0023 - rec: 0.7307 - val_auc: 0.9131 - val_loss: 0.9366 - val_prec: 0.0038 - val_rec: 1.0000 - learning_rate: 5.2626e-05\n",
            "Epoch 15/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - auc: 0.8151 - loss: 0.7322 - prec: 0.0028 - rec: 0.8815 - val_auc: 0.9441 - val_loss: 0.9329 - val_prec: 0.0039 - val_rec: 1.0000 - learning_rate: 5.2626e-05\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - auc: 0.0519 - loss: 4.5015 - prec: 4.3247e-05 - rec: 0.0123 - val_auc: 0.0104 - val_loss: 0.7251 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00 - learning_rate: 5.2626e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - auc: 0.1232 - loss: 3.7409 - prec: 2.5696e-04 - rec: 0.0739 - val_auc: 0.0115 - val_loss: 0.7591 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00 - learning_rate: 5.2626e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - auc: 0.1040 - loss: 3.0420 - prec: 2.2338e-04 - rec: 0.0666 - val_auc: 0.0115 - val_loss: 0.7806 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00 - learning_rate: 5.2626e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - auc: 0.1505 - loss: 2.7995 - prec: 3.3043e-04 - rec: 0.0951 - val_auc: 0.0108 - val_loss: 0.7975 - val_prec: 0.0000e+00 - val_rec: 0.0000e+00 - learning_rate: 2.6313e-05\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - auc: 0.8255 - loss: 0.6324 - prec: 0.0032 - rec: 0.8711 - val_auc: 0.9104 - val_loss: 0.6553 - val_prec: 0.0079 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - auc: 0.9769 - loss: 0.3775 - prec: 0.0059 - rec: 0.9815 - val_auc: 0.9537 - val_loss: 0.4540 - val_prec: 0.0410 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9799 - loss: 0.2896 - prec: 0.0120 - rec: 0.9815 - val_auc: 0.9808 - val_loss: 0.3373 - val_prec: 0.1087 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9807 - loss: 0.2296 - prec: 0.0272 - rec: 0.9815 - val_auc: 0.9909 - val_loss: 0.2626 - val_prec: 0.1667 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9810 - loss: 0.1857 - prec: 0.0564 - rec: 0.9815 - val_auc: 0.9949 - val_loss: 0.2102 - val_prec: 0.2273 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9811 - loss: 0.1537 - prec: 0.1007 - rec: 0.9815 - val_auc: 0.9968 - val_loss: 0.1721 - val_prec: 0.3125 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9813 - loss: 0.1306 - prec: 0.1514 - rec: 0.9815 - val_auc: 0.9979 - val_loss: 0.1444 - val_prec: 0.3571 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9813 - loss: 0.1137 - prec: 0.2125 - rec: 0.9815 - val_auc: 0.9983 - val_loss: 0.1241 - val_prec: 0.3571 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9813 - loss: 0.1013 - prec: 0.2814 - rec: 0.9815 - val_auc: 0.9984 - val_loss: 0.1093 - val_prec: 0.5556 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9813 - loss: 0.0919 - prec: 0.3471 - rec: 0.9815 - val_auc: 0.9988 - val_loss: 0.0975 - val_prec: 0.6250 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9813 - loss: 0.0843 - prec: 0.3762 - rec: 0.9815 - val_auc: 0.9988 - val_loss: 0.0891 - val_prec: 0.6250 - val_rec: 0.8333 - learning_rate: 9.7240e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9813 - loss: 0.0790 - prec: 0.4137 - rec: 0.9815 - val_auc: 0.9988 - val_loss: 0.0856 - val_prec: 0.6250 - val_rec: 0.8333 - learning_rate: 4.8620e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 98ms/step - auc: 0.9434 - loss: 0.5240 - prec: 0.0042 - rec: 0.9733 - val_auc: 0.9057 - val_loss: 0.6252 - val_prec: 0.0173 - val_rec: 0.8750 - learning_rate: 9.7240e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - auc: 0.9971 - loss: 0.3648 - prec: 0.0071 - rec: 1.0000 - val_auc: 0.9142 - val_loss: 0.4413 - val_prec: 0.0769 - val_rec: 0.8750 - learning_rate: 9.7240e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9988 - loss: 0.2836 - prec: 0.0162 - rec: 1.0000 - val_auc: 0.9175 - val_loss: 0.3289 - val_prec: 0.1429 - val_rec: 0.8750 - learning_rate: 9.7240e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9995 - loss: 0.2216 - prec: 0.0398 - rec: 1.0000 - val_auc: 0.9253 - val_loss: 0.2517 - val_prec: 0.2000 - val_rec: 0.8750 - learning_rate: 9.7240e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9998 - loss: 0.1745 - prec: 0.0797 - rec: 1.0000 - val_auc: 0.9194 - val_loss: 0.2004 - val_prec: 0.2414 - val_rec: 0.8750 - learning_rate: 9.7240e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - auc: 0.9999 - loss: 0.1422 - prec: 0.1213 - rec: 1.0000 - val_auc: 0.9165 - val_loss: 0.1828 - val_prec: 0.2593 - val_rec: 0.8750 - learning_rate: 4.8620e-04\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - auc: 0.9574 - loss: 0.4034 - prec: 0.0036 - rec: 0.9773 - val_auc: 0.9977 - val_loss: 0.4959 - val_prec: 0.0241 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - auc: 0.9798 - loss: 0.2753 - prec: 0.0103 - rec: 0.9523 - val_auc: 0.9977 - val_loss: 0.3463 - val_prec: 0.0683 - val_rec: 1.0000 - learning_rate: 5.0214e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - auc: 0.9870 - loss: 0.2055 - prec: 0.0257 - rec: 0.9880 - val_auc: 0.9976 - val_loss: 0.2931 - val_prec: 0.0833 - val_rec: 0.9286 - learning_rate: 2.5107e-04\n",
            "\n",
            "=== Random Search: melhores hiperparâmetros ===\n",
            "{'clf__batch_size': 512, 'clf__epochs': 20, 'clf__model__dropout': 0.0, 'clf__model__hidden_layers': 1, 'clf__model__l2': 0.0001, 'clf__model__learning_rate': np.float64(0.0005021425736625638), 'clf__model__units': 73}\n",
            "Melhor AUC-ROC (CV, subset): 0.9789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Search"
      ],
      "metadata": {
        "id": "0frFgujiqjmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "best_rs = rs.best_params_\n",
        "\n",
        "def around_units(u):\n",
        "    c = int(u)\n",
        "    return sorted(set([max(16, c//2), c, min(256, c*2)]))\n",
        "\n",
        "def around_float(v, low=1e-5, high=1e-2):\n",
        "    return sorted(set([max(low, v/2), v, min(high, v*2)]))\n",
        "\n",
        "grid_params = {\n",
        "    \"clf__model__hidden_layers\": [max(1, best_rs[\"clf__model__hidden_layers\"]-1),\n",
        "                                  best_rs[\"clf__model__hidden_layers\"],\n",
        "                                  min(4, best_rs[\"clf__model__hidden_layers\"]+1)],\n",
        "    \"clf__model__units\": around_units(best_rs[\"clf__model__units\"]),\n",
        "    \"clf__model__dropout\": [max(0.0, best_rs[\"clf__model__dropout\"]-0.1),\n",
        "                            best_rs[\"clf__model__dropout\"],\n",
        "                            min(0.5, best_rs[\"clf__model__dropout\"]+0.1)],\n",
        "    \"clf__model__l2\": sorted(set([\n",
        "        best_rs[\"clf__model__l2\"]/10 if best_rs[\"clf__model__l2\"]>0 else 0.0,\n",
        "        best_rs[\"clf__model__l2\"],\n",
        "        best_rs[\"clf__model__l2\"]*10 if best_rs[\"clf__model__l2\"]>0 else 1e-5\n",
        "    ])),\n",
        "    \"clf__model__learning_rate\": around_float(best_rs[\"clf__model__learning_rate\"], low=1e-5, high=1e-2),\n",
        "    \"clf__batch_size\": sorted(set([max(256, best_rs[\"clf__batch_size\"]//2),\n",
        "                                   best_rs[\"clf__batch_size\"],\n",
        "                                   min(2048, best_rs[\"clf__batch_size\"]*2)])),\n",
        "    \"clf__epochs\": sorted(set([max(12, best_rs[\"clf__epochs\"]-5),\n",
        "                               best_rs[\"clf__epochs\"],\n",
        "                               min(30, best_rs[\"clf__epochs\"]+5)])),\n",
        "}\n",
        "\n",
        "base_clf2 = KerasClassifier(\n",
        "    model=build_mlp,\n",
        "    verbose=0,\n",
        "    callbacks=[early_stop_search, reduce_lr_search],  # callbacks rápidos também no grid\n",
        ")\n",
        "\n",
        "pipe_gs = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", base_clf2),\n",
        "])\n",
        "\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=SEED)  # igual ao RS\n",
        "\n",
        "gs = GridSearchCV(\n",
        "    estimator=pipe_gs,\n",
        "    param_grid=grid_params,\n",
        "    scoring=safe_auc_scorer,\n",
        "    refit=True,\n",
        "    cv=cv,\n",
        "    verbose=1,\n",
        "    n_jobs=1,\n",
        ")\n",
        "\n",
        "gs.fit(X_rs, y_rs, **{**FIT_KW, \"clf__validation_split\": 0.1})\n",
        "\n",
        "print(\"\\n Grid Search: melhores hiperparâmetros\")\n",
        "print(gs.best_params_)\n",
        "print(f\"Melhor AUC-ROC (CV, subset): {gs.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "oktZTT9Fqk9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555a5cbd-cce7-492b-c4be-6eaf12848f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 2187 candidates, totalling 4374 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação final - Comparação e Análise"
      ],
      "metadata": {
        "id": "OUepFUS9q4q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#early stopping normal para o treino final\n",
        "early_stop_final = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_auc\", patience=5, mode=\"max\", restore_best_weights=True, min_delta=1e-4\n",
        ")\n",
        "reduce_lr_final = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_auc\", factor=0.5, patience=2, mode=\"max\", min_lr=1e-6\n",
        ")\n",
        "\n",
        "best_pipe = gs.best_estimator_\n",
        "best_pipe.set_params(clf__callbacks=[early_stop_final, reduce_lr_final])\n",
        "\n",
        "# Treino FINAL no treino COMPLETO\n",
        "best_pipe.fit(X_train, y_train, **FIT_KW)\n",
        "\n",
        "# Métricas no TESTE do modelo otimizado\n",
        "tuned_metrics = evaluate(best_pipe, X_test, y_test, name=\"Otimizado (Random+Grid rápido)\")\n",
        "\n",
        "# Comparação lado a lado\n",
        "comparison = pd.DataFrame([baseline_metrics, tuned_metrics]).set_index(\"model\")\n",
        "print(\"\\n Comparação (Baseline vs Otimizado)\")\n",
        "display(comparison)\n",
        "\n",
        "# Ganhos absolutos\n",
        "improve = {\n",
        "    \"AUC-ROC\": tuned_metrics[\"auc\"] - baseline_metrics[\"auc\"],\n",
        "    \"Precisão\": tuned_metrics[\"precision\"] - baseline_metrics[\"precision\"],\n",
        "    \"Recall\": tuned_metrics[\"recall\"] - baseline_metrics[\"recall\"],\n",
        "    \"F1-score\": tuned_metrics[\"f1\"] - baseline_metrics[\"f1\"],\n",
        "}\n",
        "print(\"\\n Ganho (Otimizado - Baseline)\")\n",
        "for k, v in improve.items():\n",
        "    print(f\"{k}: {v:+.4f}\")\n",
        "\n",
        "# Análise curta\n",
        "print(\"\\n Análise\")\n",
        "msgs = []\n",
        "if improve[\"AUC-ROC\"] > 0:\n",
        "    msgs.append(f\"A separabilidade melhorou (ΔAUC={improve['AUC-ROC']:+.4f}).\")\n",
        "else:\n",
        "    msgs.append(f\"A separabilidade não melhorou (ΔAUC={improve['AUC-ROC']:+.4f}).\")\n",
        "\n",
        "if improve[\"Precisão\"] > 0 and improve[\"Recall\"] >= -0.01:\n",
        "    msgs.append(\"Ganho de precisão sem queda relevante de recall.\")\n",
        "elif improve[\"Precisão\"] > 0 and improve[\"Recall\"] < -0.01:\n",
        "    msgs.append(\"Precisão subiu com alguma queda de recall (trade-off).\")\n",
        "elif improve[\"Precisão\"] <= 0 and improve[\"Recall\"] > 0:\n",
        "    msgs.append(\"Recall subiu mas a precisão caiu (mais FP).\")\n",
        "else:\n",
        "    msgs.append(\"Sem melhora clara — amplie o espaço de busca ou ajuste o limiar de decisão.\")\n",
        "\n",
        "if improve[\"F1-score\"] > 0:\n",
        "    msgs.append(f\"O F1 (equilíbrio P/R) melhorou (ΔF1={improve['F1-score']:+.4f}).\")\n",
        "else:\n",
        "    msgs.append(f\"O F1 não melhorou (ΔF1={improve['F1-score']:+.4f}).\")\n",
        "\n",
        "print(\" \".join(msgs))"
      ],
      "metadata": {
        "id": "zT7ArnHCqz2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}